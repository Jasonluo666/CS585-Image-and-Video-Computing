{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS585 Assignment 2 Programming Part\n",
    "### Author: Jiangshan Luo\n",
    "### Uni ID: U89971259"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue;\"> In this notebook, I will present the method for my Python program to handle each single task in the HW2 requirement by processing an image individually and show the result for each stage.</span> \n",
    "### <span style=\"color:blue;\"> The real program (process all images) is shown in the last cell which is only the merged version of the cells above. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, abspath, exists\n",
    "from collections import Counter\n",
    "from IPython.display import Image as print_image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data_path = abspath('./shapes_dataset/shapes_train2018')\n",
    "data_list = [join(data_path, file) for file in listdir(data_path) if isfile(join(data_path, file)) and 'jpeg' in file]\n",
    "annotation_path = abspath('./shapes_dataset/annotations')\n",
    "annotation_list = [join(annotation_path, file) for file in listdir(annotation_path) if isfile(join(annotation_path, file)) and 'png' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_case = 1048\n",
    "output_file = './output/' + str(test_case)\n",
    "if not exists(output_file):\n",
    "    makedirs(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determine the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The background color is 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nmErby2Kh2IglVZFIaJwJFZXRTXwRRRRX/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(data_list[test_case - 1000])\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# medianBlur -> remove the noise\n",
    "img_gray = cv2.medianBlur(img_gray,5)\n",
    "\n",
    "# find the background color\n",
    "boarder_pixel = []\n",
    "for x in range(img_gray.shape[0]):\n",
    "    for y in range(img_gray.shape[1]):\n",
    "        if x == 0 or y == 0:\n",
    "            boarder_pixel.append(img_gray[x][y])\n",
    "            \n",
    "# assume background color is the pixel value that has the maxi|mum frequency\n",
    "background_color, frequency = Counter(boarder_pixel).most_common(1)[0]\n",
    "print('The background color is', background_color)\n",
    "\n",
    "img_withoutBG = img_gray.copy()\n",
    "for x in range(img_withoutBG.shape[0]):\n",
    "    for y in range(img_withoutBG.shape[1]):\n",
    "        if(np.abs(img_withoutBG[x][y] - background_color)) < 10:\n",
    "            img_withoutBG[x][y] = 0\n",
    "            '''# Floodfill\n",
    "            h, w = img_gray.shape[:2]\n",
    "            mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "            cv2.floodFill(img_gray, mask, (x, y), 0)\n",
    "            cv2.imwrite(str(count)+'.jpeg',img_gray)\n",
    "            count = count + 1'''\n",
    "     \n",
    "cv2.imwrite(output_file + '/img_withoutBG.jpeg',img_withoutBG)\n",
    "print_image(output_file + '/img_withoutBG.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label every shape blob based on color\n",
    "### <span style=\"color:blue;\">2.1 remove the noises <span/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# test remove_surrounding_noise\\ntest_img = img_noNoise.copy()\\nremove_surrounding_noise(test_img, blob_colors)\\ncv2.imwrite('2.jpeg',test_img)\\n\\nblob_detector=[]\\nfor x in range(test_img.shape[0]):\\n    for y in range(test_img.shape[1]):\\n        if(test_img[x][y] != 0):\\n            blob_detector.append(test_img[x][y])\\nCounter(blob_detector)\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "bfs(img, flag_img, seed_point=[0,0])\n",
    "\n",
    "    use BFS to find the size of each blob\n",
    "    input: \n",
    "        - img: src image\n",
    "        - flag_img: boolean map used to mark the blob\n",
    "        - seed_point: start searching point\n",
    "    output:\n",
    "        - count: size of the blob\n",
    "'''\n",
    "def bfs(img, flag_img, seed_point=[0,0]):\n",
    "    count = 1\n",
    "    matrix = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "    neighbor = [0,0]\n",
    "    flag_img[seed_point[0]][seed_point[1]] = 1\n",
    "    \n",
    "    queue = [seed_point]\n",
    "    \n",
    "    while len(queue) > 0:\n",
    "        # enqueue and dequeue\n",
    "        current_point = queue[0]\n",
    "        del queue[0]\n",
    "        \n",
    "        for element in matrix:\n",
    "            neighbor[0] = current_point[0] + element[0]\n",
    "            neighbor[1] = current_point[1] + element[1]\n",
    "            if neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1]:\n",
    "                if img[neighbor[0]][neighbor[1]] == img[seed_point[0]][seed_point[1]] and flag_img[neighbor[0]][neighbor[1]] == 0:\n",
    "                    count = count + 1\n",
    "                    flag_img[neighbor[0]][neighbor[1]] = 1\n",
    "                    queue.append(neighbor.copy())\n",
    "    \n",
    "    return count\n",
    "\n",
    "'''# test bfs\n",
    "flag = np.zeros_like(img_withoutBG)\n",
    "bfs(img_withoutBG, flag)'''\n",
    "\n",
    "'''\n",
    "remove_surrounding_noise(img, blob_color = [])\n",
    "\n",
    "    remove noise with colors other than blobs and small size blobs\n",
    "    input:\n",
    "        - img: src image\n",
    "        - blob_color: the colors of the blobs\n",
    "'''\n",
    "def remove_surrounding_noise(img, blob_color = []):\n",
    "    search_map = np.zeros_like(img)\n",
    "    \n",
    "    # remove noise with the blob colors\n",
    "    for x in range(img.shape[0]):\n",
    "        for y in range(img.shape[1]):\n",
    "            if img[x][y] in blob_color:\n",
    "                if search_map[x][y] == 0:\n",
    "                    # find the size of the image\n",
    "                    flag_map = np.zeros_like(img)\n",
    "                    blob_size = bfs(img, flag_map, [x,y])\n",
    "\n",
    "                    # update the search map\n",
    "                    search_map += flag_map\n",
    "\n",
    "                    # remove the blobs which size < 300 pixels\n",
    "                    if blob_size < 300:\n",
    "                        for x_1 in range(flag_map.shape[0]):\n",
    "                            for y_1 in range(flag_map.shape[1]):\n",
    "                                if(flag_map[x_1][y_1] == 1):\n",
    "                                    img[x_1][y_1] = 0\n",
    "            # remove noise with colors other than blobs\n",
    "            else:\n",
    "                img[x][y] = 0\n",
    "\n",
    "'''# test remove_surrounding_noise\n",
    "test_img = img_noNoise.copy()\n",
    "remove_surrounding_noise(test_img, blob_colors)\n",
    "cv2.imwrite('2.jpeg',test_img)\n",
    "\n",
    "blob_detector=[]\n",
    "for x in range(test_img.shape[0]):\n",
    "    for y in range(test_img.shape[1]):\n",
    "        if(test_img[x][y] != 0):\n",
    "            blob_detector.append(test_img[x][y])\n",
    "Counter(blob_detector)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue;\">2.2 label blobs <span/>\n",
    "every unique grayscale color value remain in the image represent a blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nUUUV/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_detector = []\n",
    "for x in range(img_withoutBG.shape[0]):\n",
    "    for y in range(img_withoutBG.shape[1]):\n",
    "        if(img_withoutBG[x][y] != 0):\n",
    "            blob_detector.append(img_withoutBG[x][y])\n",
    "\n",
    "# assume blobs have more than 500 pixels\n",
    "counter_keys = list(Counter(blob_detector).keys())\n",
    "blob_colors = [x for x in counter_keys if Counter(blob_detector)[x] > 300]\n",
    "\n",
    "img_noNoise = img_withoutBG.copy()\n",
    "\n",
    "# remove the noise (non-blobs-color pixels and small size blobs)\n",
    "remove_surrounding_noise(img_noNoise, blob_colors)\n",
    "\n",
    "# medianBlur -> remove the noise\n",
    "img_noNoise = cv2.medianBlur(img_noNoise,5)\n",
    "\n",
    "'''#recognize the shapes\n",
    "for x in range(img_noNoise.shape[0]):\n",
    "    for y in range(img_noNoise.shape[1]):\n",
    "        if(img_noNoise[x][y] in blob_colors):\n",
    "            img_noNoise[x][y] = 255'''\n",
    "\n",
    "obj_num = 1\n",
    "for color in blob_colors:\n",
    "    blob_image = np.zeros_like(img_noNoise)\n",
    "    for x in range(img_noNoise.shape[0]):\n",
    "        for y in range(img_noNoise.shape[1]):\n",
    "            if img_noNoise[x][y] == color:\n",
    "                blob_image[x][y] = 255\n",
    "    cv2.imwrite(output_file + '/blob_' + str(obj_num) + '.jpeg', blob_image)\n",
    "    obj_num += 1\n",
    "\n",
    "cv2.imwrite(output_file + '/img_noNoise.jpeg',img_noNoise)\n",
    "print_image(output_file + '/img_noNoise.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement the boundary following algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# test boundary_following\\ntest_contour = boundary_following(img_noNoise, blob_colors)\\ncv2.imwrite('3.jpeg', test_contour[0])\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "boundary_following(img, blob_color)\n",
    "    \n",
    "    implementation of the boundary following algorithm\n",
    "    input: \n",
    "        - img: src image\n",
    "        - blob_color: the colors of the blobs\n",
    "    output:\n",
    "        - contour_map: a list of contour images\n",
    "'''\n",
    "def boundary_following(img, blob_color):\n",
    "    contour_map = []\n",
    "    search_map = np.zeros_like(img)\n",
    "    # clockwise start from the west\n",
    "    clockwise_matrix = [[0,-1],[-1,-1],[-1,0],[-1,1],[0,1],[1,1],[1,0],[1,-1]]\n",
    "    # boundary pixel outside R\n",
    "    b = [0,0]\n",
    "    # current pixel inside object on boundary\n",
    "    c = [0,0]\n",
    "    \n",
    "    for x in range(img.shape[0]):\n",
    "        for y in range(img.shape[1]):\n",
    "            # find the start pixel\n",
    "            if img[x][y] in blob_color and search_map[x][y] == 0 and bfs(img, search_map, [x,y]) > 300:\n",
    "                # use bfs() to update the search_map -> make sure every blob only be computed once\n",
    "                pixel_color = img[x][y]\n",
    "                \n",
    "                contour = np.zeros_like(img)\n",
    "                c = [x,y]\n",
    "                b[0] = c[0] + clockwise_matrix[0][0]\n",
    "                b[1] = c[1] + clockwise_matrix[0][1]\n",
    "                \n",
    "                finish_flag = False\n",
    "                while not finish_flag:\n",
    "                    # find next neighbor (b is supposed to start from the west neighbor outside R)\n",
    "                    neighbor = b.copy()\n",
    "                    start_index = clockwise_matrix.index([neighbor[0] - c[0], neighbor[1] - c[1]])\n",
    "                    \n",
    "                    for loop_time in range(8):\n",
    "                        neighbor[0] = c[0] + clockwise_matrix[(start_index + loop_time) % 8][0]\n",
    "                        neighbor[1] = c[1] + clockwise_matrix[(start_index + loop_time) % 8][1]\n",
    "                        \n",
    "                        # find the first neighbor inside R, update b and c\n",
    "                        if neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1] \\\n",
    "                        and img[neighbor[0]][neighbor[1]] == pixel_color:\n",
    "                                c = neighbor.copy()\n",
    "                                b = last_neighbor.copy()\n",
    "                                contour[neighbor[0]][neighbor[1]] = 255\n",
    "                                \n",
    "                                # finish\n",
    "                                if neighbor == [x,y]:\n",
    "                                    finish_flag = True\n",
    "                                \n",
    "                                break\n",
    "                        else:\n",
    "                            last_neighbor = neighbor.copy()\n",
    "                \n",
    "                contour_map.append(contour.copy())\n",
    "    \n",
    "    return np.array(contour_map)\n",
    "\n",
    "'''# test boundary_following\n",
    "test_contour = boundary_following(img_noNoise, blob_colors)\n",
    "cv2.imwrite('3.jpeg', test_contour[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours = boundary_following(img_noNoise, blob_colors)\n",
    "\n",
    "merged_contour = np.zeros_like(img_noNoise)\n",
    "for contour in contours:\n",
    "    merged_contour += contour\n",
    "\n",
    "cv2.imwrite(output_file + '/boundary_following.jpeg', merged_contour)\n",
    "print_image(output_file + '/boundary_following.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the boundary following algorithm with cv2.findContours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nKS+WrssaAyXdy0UFtDJf3klxfXKWluLi5nMKMPP6KKK//9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, contours_opencv, hierarchy = cv2.findContours(img_noNoise, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "image_background = np.zeros_like(img_noNoise)\n",
    "# contourIdx=-1 draw all contours\n",
    "opencv_drawContours_result = cv2.drawContours(image_background, contours_opencv, contourIdx=-1, color=255, thickness=1)\n",
    "\n",
    "cv2.imwrite(output_file + '/opencv_drawContours_result.jpeg',opencv_drawContours_result)\n",
    "print_image(output_file + '/opencv_drawContours_result.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Classify boundary pixels (background/another blob/image boundary)\n",
    "use the contours and blob colors gained previously to classify the boundary pixel:\n",
    "\n",
    "    - against background: have background neighbor pixel\n",
    "    - against image boundary: image boundary pixel\n",
    "    - against another blob: have neighbor pixel that belongs to one of the other blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nabhZadYWyxQQBsAkAcu5CoplkLSOI03u20Vl0UUV/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mark three categories with grayscale value: 80, 160, 240\n",
    "classified_contours = []\n",
    "N4_neighbor = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "neighbor = [0,0]\n",
    "\n",
    "for contour in contours:\n",
    "    classified_contour = contour.copy()\n",
    "    \n",
    "    for x in range(classified_contour.shape[0]):\n",
    "        for y in range(classified_contour.shape[1]):\n",
    "            # classify each pixel in the contour\n",
    "            if classified_contour[x][y] == 255:\n",
    "                is_background = False\n",
    "                is_boundary = False\n",
    "                \n",
    "                # find the characteristics of its neighbors\n",
    "                for element in N4_neighbor:\n",
    "                    neighbor[0] = x + element[0]\n",
    "                    neighbor[1] = y + element[1]\n",
    "                    \n",
    "                    # iamge boundary\n",
    "                    if not (neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1]):\n",
    "                        is_boundary = True\n",
    "                        break\n",
    "                    # background\n",
    "                    elif img_noNoise[neighbor[0]][neighbor[1]] == 0:\n",
    "                        is_background = True\n",
    "                        break\n",
    "                \n",
    "                if(is_background):\n",
    "                    classified_contour[x][y] = 80\n",
    "                elif(is_boundary):\n",
    "                    classified_contour[x][y] = 160\n",
    "                # others belongs to contour against other blobs\n",
    "                else:\n",
    "                    classified_contour[x][y] = 240\n",
    "\n",
    "    classified_contours.append(classified_contour)\n",
    "\n",
    "# classified_contours contains classification info of each contour\n",
    "merged_classified_contour = np.zeros_like(img_noNoise)\n",
    "for contour in classified_contours:\n",
    "    merged_classified_contour += contour\n",
    "    \n",
    "cv2.imwrite(output_file + '/merged_classified_contour.jpeg',merged_classified_contour)\n",
    "print_image(output_file + '/merged_classified_contour.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Blob shape recognition\n",
    "\n",
    "use different attributes of the blobs to recognize their shape. For this task, part of the blob contours will be used (those against the background) because they are not influenced by other factors and are the original shape of the blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centorids and compactness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.936781609195403, 106.35057471264368], [70.13245033112582, 77.01986754966887], [104.08982035928143, 61.34730538922156]]\n",
      "[14.60492040520984, 15.343876177658142, 15.597874720357941]\n"
     ]
    }
   ],
   "source": [
    "# find centorids of blobs in order to determine the positions of them in the annotation file\n",
    "centorids = []\n",
    "compactness = []\n",
    "\n",
    "for contour in classified_contours:\n",
    "    sum_contour = [0,0]\n",
    "    pixel_count = 0\n",
    "    blob_area = 0\n",
    "    compute_area= False\n",
    "    \n",
    "    for x in range(contour.shape[0]):\n",
    "        for y in range(contour.shape[1]):\n",
    "            if contour[x][y] != 0:\n",
    "                sum_contour[0] += x\n",
    "                sum_contour[1] += y\n",
    "                pixel_count += 1\n",
    "                \n",
    "                if not compute_area:\n",
    "                    blob_area = bfs(img_noNoise, np.zeros_like(img_noNoise), [x,y])\n",
    "                    compute_area = True\n",
    "    \n",
    "    centorids.append([sum_contour[0] / pixel_count, sum_contour[1] / pixel_count])\n",
    "    compactness.append(pixel_count ** 2 / blob_area)\n",
    "\n",
    "print(centorids)\n",
    "print(compactness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approxPolyDP guess the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 12, 11]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordered contour\n",
    "original_contours = classified_contours.copy()\n",
    "for index in range(len(original_contours)):\n",
    "    for x in range(original_contours[index].shape[0]):\n",
    "        for y in range(original_contours[index].shape[1]):\n",
    "            if original_contours[index][x][y] != 80:\n",
    "                original_contours[index][x][y] = 0\n",
    "\n",
    "shapes = []\n",
    "for contour in original_contours:\n",
    "    shape = 0\n",
    "    _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt_piece in contours_opencv:\n",
    "        shape += len(cv2.approxPolyDP(np.array(cnt_piece), 10, closed=False))\n",
    "    \n",
    "    shapes.append(shape)\n",
    "    \n",
    "shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matchShapes compute the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.7976931348623157e+308, 1.7976931348623157e+308],\n",
       " [0.052851530068600994, 0.46777003930596267],\n",
       " [1.7976931348623157e+308, 1.7976931348623157e+308]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_match = []\n",
    "square_sample = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],\\\n",
    "                          [1,5],[2,5],[3,5],[4,5],[5,5],\\\n",
    "                          [5,4],[5,3],[5,2],[5,1],[5,0],\\\n",
    "                          [4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "triangle_sample = np.array([[0,0],[1,np.sqrt(3)],[2,2*np.sqrt(3)],[3,3*np.sqrt(3)],\\\n",
    "                            [4,2*np.sqrt(3)],[5,np.sqrt(3)],[6,0],\\\n",
    "                            [5,0],[4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "\n",
    "for contour in original_contours:\n",
    "    _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    max_piece_index = np.argmax([len(x) for x in contours_opencv])\n",
    "    \n",
    "    square_match = cv2.matchShapes(contours_opencv[max_piece_index], square_sample, 1, 0)\n",
    "    triangle_match = cv2.matchShapes(contours_opencv[max_piece_index], triangle_sample, 1, 0)\n",
    "    \n",
    "    shape_match.append([square_match, triangle_match])\n",
    "\n",
    "shape_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of the recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['square', 'circle', 'circle']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clssified_blobs = []\n",
    "for blob_index in range(len(contours)):\n",
    "    # considered to be circule\n",
    "    if shapes[blob_index] > 10 or (shapes[blob_index] >= 10 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "        clssified_blobs.append('circle')\n",
    "    # considered to be triangle\n",
    "    elif (shape_match[blob_index][1] < 2 and shape_match[blob_index][0] * 3 < shape_match[blob_index][1]) or (shapes[blob_index] >= 6 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "        clssified_blobs.append('triangle')\n",
    "    # considered to be square\n",
    "    else:\n",
    "        clssified_blobs.append('square')\n",
    "\n",
    "clssified_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'circle_total': 1,\n",
       " 'circle_true_predict': 1,\n",
       " 'square_total': 1,\n",
       " 'square_true_predict': 1,\n",
       " 'triangle_total': 1,\n",
       " 'triangle_true_predict': 0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_annotations = [x for x in annotation_list if str(test_case) in x and 'crowd' not in x]\n",
    "\n",
    "evaluation = {'triangle_total': 0, 'triangle_true_predict': 0,\\\n",
    "              'square_total': 0, 'square_true_predict': 0,\\\n",
    "              'circle_total': 0, 'circle_true_predict': 0}\n",
    "\n",
    "for file in relevant_annotations:\n",
    "    if 'triangle' in file:\n",
    "        evaluation['triangle_total'] += 1\n",
    "    elif 'square' in file:\n",
    "        evaluation['square_total'] += 1\n",
    "    elif 'circle' in file:\n",
    "        evaluation['circle_total'] += 1\n",
    "    \n",
    "    matched_index = -1\n",
    "    verify_img = cv2.imread(file)\n",
    "    verify_img = cv2.cvtColor(verify_img, cv2.COLOR_BGR2GRAY)\n",
    "    for contour_index in range(len(original_contours)):\n",
    "        if matched_index != -1:\n",
    "            break\n",
    "        for x in range(original_contours[contour_index].shape[0]):\n",
    "            for y in range(original_contours[contour_index].shape[1]):\n",
    "                if original_contours[contour_index][x][y] != 0 and verify_img[x][y] != 0:\n",
    "                    matched_index = contour_index\n",
    "                    break\n",
    "    \n",
    "    if clssified_blobs[matched_index] in file:\n",
    "        evaluation[clssified_blobs[matched_index] + '_true_predict'] += 1\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 67.0 %\n"
     ]
    }
   ],
   "source": [
    "precision = (evaluation['triangle_true_predict'] + evaluation['square_true_predict'] + evaluation['circle_true_predict']) / \\\n",
    "            (evaluation['triangle_total'] + evaluation['square_total'] + evaluation['circle_total'])\n",
    "\n",
    "print('precision:', np.ceil(precision * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_file = open(output_file + '/Evaluation.txt','w')\n",
    "txt_file.write(str(evaluation))\n",
    "txt_file.write('\\n')\n",
    "txt_file.write('precision:' + str(np.ceil(precision * 100)) + '%')\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all images (merge the code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The background color is 178\n",
      "[[35.004347826086956, 90.25652173913043]]\n",
      "[14.308899107384367]\n",
      "precision: 0.0 %\n",
      "The background color is 139\n",
      "[[27.11464968152866, 77.97452229299363], [34.162962962962965, 34.39259259259259], [85.5618556701031, 23.5], [99.3953488372093, 100.86976744186046]]\n",
      "[9.883319967923015, 12.339201083276913, 14.893549663632767, 15.052100293064148]\n",
      "precision: 50.0 %\n",
      "The background color is 40\n",
      "[[19.961904761904762, 26.723809523809525], [54.91379310344828, 33.775862068965516], [103.92361111111111, 30.930555555555557]]\n",
      "[12.049180327868852, 10.186222558667676, 13.750663129973475]\n",
      "precision: 34.0 %\n",
      "The background color is 86\n",
      "[[48.720670391061454, 40.11731843575419], [96.4493670886076, 26.9873417721519]]\n",
      "[17.394679695982628, 15.90063694267516]\n",
      "precision: 100.0 %\n",
      "The background color is 127\n",
      "[[26.048387096774192, 66.14516129032258], [78.7289156626506, 84.26506024096386]]\n",
      "[9.713202779532534, 10.16451493913685]\n",
      "precision: 50.0 %\n",
      "The background color is 191\n",
      "[[56.845360824742265, 23.49484536082474], [81.76190476190476, 66.64285714285714], [96.81547619047619, 26.339285714285715]]\n",
      "[16.166666666666668, 11.396984924623116, 11.191118160190324]\n",
      "precision: 34.0 %\n",
      "The background color is 211\n",
      "[[58.52212389380531, 83.30973451327434], [89.56223175965665, 45.31330472103004]]\n",
      "[14.778935185185185, 15.418631070718545]\n",
      "precision: 50.0 %\n",
      "The background color is 125\n",
      "[[70.98780487804878, 68.6951219512195], [105.19402985074628, 37.55223880597015]]\n",
      "[10.651881188118812, 13.510910458991724]\n",
      "precision: 100.0 %\n",
      "The background color is 136\n",
      "[[74.65873015873017, 76.33333333333333]]\n",
      "[14.341463414634147]\n",
      "precision: 100.0 %\n",
      "The background color is 187\n",
      "[[35.125786163522015, 42.125786163522015]]\n",
      "[13.829868708971553]\n",
      "precision: 0.0 %\n",
      "The background color is 63\n",
      "[[60.0, 39.015306122448976]]\n",
      "[13.878612716763005]\n",
      "precision: 0.0 %\n",
      "The background color is 179\n",
      "[[24.811023622047244, 48.22834645669291], [102.63414634146342, 97.37073170731708]]\n",
      "[10.144025157232704, 14.792326645547343]\n",
      "precision: 0.0 %\n",
      "The background color is 154\n",
      "[[48.074074074074076, 102.74691358024691], [33.258278145695364, 26.5364238410596], [58.820809248554916, 54.98843930635838]]\n",
      "[15.056798623063683, 14.691365979381443, 17.005113636363635]\n"
     ]
    }
   ],
   "source": [
    "overall_evaluation = {'triangle_total': 0, 'triangle_true_predict': 0,\\\n",
    "                  'square_total': 0, 'square_true_predict': 0,\\\n",
    "                  'circle_total': 0, 'circle_true_predict': 0}\n",
    "\n",
    "for case in range(len(data_list)):\n",
    "    case += 1000\n",
    "    output_file = './output/' + str(case)\n",
    "    if not exists(output_file):\n",
    "        makedirs(output_file)\n",
    "\n",
    "    img = cv2.imread(data_list[case - 1000])\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # medianBlur -> remove the noise\n",
    "    img_gray = cv2.medianBlur(img_gray,5)\n",
    "\n",
    "    # find the background color\n",
    "    boarder_pixel = []\n",
    "    for x in range(img_gray.shape[0]):\n",
    "        for y in range(img_gray.shape[1]):\n",
    "            if x == 0 or y == 0:\n",
    "                boarder_pixel.append(img_gray[x][y])\n",
    "\n",
    "    # assume background color is the pixel value that has the maxi|mum frequency\n",
    "    background_color, frequency = Counter(boarder_pixel).most_common(1)[0]\n",
    "    print('The background color is', background_color)\n",
    "\n",
    "    img_withoutBG = img_gray.copy()\n",
    "    for x in range(img_withoutBG.shape[0]):\n",
    "        for y in range(img_withoutBG.shape[1]):\n",
    "            if(img_withoutBG[x][y] == background_color):\n",
    "                img_withoutBG[x][y] = 0\n",
    "                '''# Floodfill\n",
    "                h, w = img_gray.shape[:2]\n",
    "                mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "                cv2.floodFill(img_gray, mask, (x, y), 0)\n",
    "                cv2.imwrite(str(count)+'.jpeg',img_gray)\n",
    "                count = count + 1'''\n",
    "\n",
    "    cv2.imwrite(output_file + '/img_withoutBG.jpeg',img_withoutBG)\n",
    "    print_image(output_file + '/img_withoutBG.jpeg')\n",
    "\n",
    "    blob_detector = []\n",
    "    for x in range(img_withoutBG.shape[0]):\n",
    "        for y in range(img_withoutBG.shape[1]):\n",
    "            if(img_withoutBG[x][y] != 0):\n",
    "                blob_detector.append(img_withoutBG[x][y])\n",
    "\n",
    "    # assume blobs have more than 500 pixels\n",
    "    counter_keys = list(Counter(blob_detector).keys())\n",
    "    blob_colors = [x for x in counter_keys if Counter(blob_detector)[x] > 300]\n",
    "\n",
    "    img_noNoise = img_withoutBG.copy()\n",
    "\n",
    "    # remove the noise (non-blobs-color pixels and small size blobs)\n",
    "    remove_surrounding_noise(img_noNoise, blob_colors)\n",
    "\n",
    "    # medianBlur -> remove the noise\n",
    "    img_noNoise = cv2.medianBlur(img_noNoise,5)\n",
    "\n",
    "    '''#recognize the shapes\n",
    "    for x in range(img_noNoise.shape[0]):\n",
    "        for y in range(img_noNoise.shape[1]):\n",
    "            if(img_noNoise[x][y] in blob_colors):\n",
    "                img_noNoise[x][y] = 255'''\n",
    "\n",
    "    cv2.imwrite(output_file + '/img_noNoise.jpeg',img_noNoise)\n",
    "    print_image(output_file + '/img_noNoise.jpeg')\n",
    "    \n",
    "    obj_num = 1\n",
    "    for color in blob_colors:\n",
    "        blob_image = np.zeros_like(img_noNoise)\n",
    "        for x in range(img_noNoise.shape[0]):\n",
    "            for y in range(img_noNoise.shape[1]):\n",
    "                if img_noNoise[x][y] == color:\n",
    "                    blob_image[x][y] = 255\n",
    "        cv2.imwrite(output_file + '/blob_' + str(obj_num) + '.jpeg', blob_image)\n",
    "        obj_num += 1\n",
    "\n",
    "    contours = boundary_following(img_noNoise, blob_colors)\n",
    "\n",
    "    merged_contour = np.zeros_like(img_noNoise)\n",
    "    for contour in contours:\n",
    "        merged_contour += contour\n",
    "\n",
    "    cv2.imwrite(output_file + '/boundary_following.jpeg', merged_contour)\n",
    "    print_image(output_file + '/boundary_following.jpeg')\n",
    "\n",
    "    _, contours_opencv, hierarchy = cv2.findContours(img_noNoise, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    image_background = np.zeros_like(img_noNoise)\n",
    "    # contourIdx=-1 draw all contours\n",
    "    opencv_drawContours_result = cv2.drawContours(image_background, contours_opencv, contourIdx=-1, color=255, thickness=1)\n",
    "\n",
    "    cv2.imwrite(output_file + '/opencv_drawContours_result.jpeg',opencv_drawContours_result)\n",
    "    print_image(output_file + '/opencv_drawContours_result.jpeg')\n",
    "\n",
    "    # mark three categories with grayscale value: 80, 160, 240\n",
    "    classified_contours = []\n",
    "    N4_neighbor = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "    neighbor = [0,0]\n",
    "\n",
    "    for contour in contours:\n",
    "        classified_contour = contour.copy()\n",
    "\n",
    "        for x in range(classified_contour.shape[0]):\n",
    "            for y in range(classified_contour.shape[1]):\n",
    "                # classify each pixel in the contour\n",
    "                if classified_contour[x][y] == 255:\n",
    "                    is_background = False\n",
    "                    is_boundary = False\n",
    "\n",
    "                    # find the characteristics of its neighbors\n",
    "                    for element in N4_neighbor:\n",
    "                        neighbor[0] = x + element[0]\n",
    "                        neighbor[1] = y + element[1]\n",
    "\n",
    "                        # iamge boundary\n",
    "                        if not (neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1]):\n",
    "                            is_boundary = True\n",
    "                            break\n",
    "                        # background\n",
    "                        elif img_noNoise[neighbor[0]][neighbor[1]] == 0:\n",
    "                            is_background = True\n",
    "                            break\n",
    "\n",
    "                    if(is_background):\n",
    "                        classified_contour[x][y] = 80\n",
    "                    elif(is_boundary):\n",
    "                        classified_contour[x][y] = 160\n",
    "                    # others belongs to contour against other blobs\n",
    "                    else:\n",
    "                        classified_contour[x][y] = 240\n",
    "\n",
    "        classified_contours.append(classified_contour)\n",
    "\n",
    "    # classified_contours contains classification info of each contour\n",
    "    merged_classified_contour = np.zeros_like(img_noNoise)\n",
    "    for contour in classified_contours:\n",
    "        merged_classified_contour += contour\n",
    "\n",
    "    cv2.imwrite(output_file + '/merged_classified_contour.jpeg',merged_classified_contour)\n",
    "    print_image(output_file + '/merged_classified_contour.jpeg')\n",
    "\n",
    "    # find centorids of blobs in order to determine the positions of them in the annotation file\n",
    "    centorids = []\n",
    "    compactness = []\n",
    "\n",
    "    for contour in classified_contours:\n",
    "        sum_contour = [0,0]\n",
    "        pixel_count = 0\n",
    "        blob_area = 0\n",
    "        compute_area= False\n",
    "\n",
    "        for x in range(contour.shape[0]):\n",
    "            for y in range(contour.shape[1]):\n",
    "                if contour[x][y] != 0:\n",
    "                    sum_contour[0] += x\n",
    "                    sum_contour[1] += y\n",
    "                    pixel_count += 1\n",
    "\n",
    "                    if not compute_area:\n",
    "                        blob_area = bfs(img_noNoise, np.zeros_like(img_noNoise), [x,y])\n",
    "                        compute_area = True\n",
    "\n",
    "        centorids.append([sum_contour[0] / pixel_count, sum_contour[1] / pixel_count])\n",
    "        compactness.append(pixel_count ** 2 / blob_area)\n",
    "\n",
    "    print(centorids)\n",
    "    print(compactness)\n",
    "\n",
    "    # ordered contour\n",
    "    original_contours = classified_contours.copy()\n",
    "    for index in range(len(original_contours)):\n",
    "        for x in range(original_contours[index].shape[0]):\n",
    "            for y in range(original_contours[index].shape[1]):\n",
    "                if original_contours[index][x][y] != 80:\n",
    "                    original_contours[index][x][y] = 0\n",
    "\n",
    "    shapes = []\n",
    "    for contour in original_contours:\n",
    "        shape = 0\n",
    "        _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt_piece in contours_opencv:\n",
    "            shape += len(cv2.approxPolyDP(np.array(cnt_piece), 10, closed=False))\n",
    "\n",
    "        shapes.append(shape)\n",
    "\n",
    "    shapes\n",
    "\n",
    "    shape_match = []\n",
    "    square_sample = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],\\\n",
    "                              [1,5],[2,5],[3,5],[4,5],[5,5],\\\n",
    "                              [5,4],[5,3],[5,2],[5,1],[5,0],\\\n",
    "                              [4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "    triangle_sample = np.array([[0,0],[1,np.sqrt(3)],[2,2*np.sqrt(3)],[3,3*np.sqrt(3)],\\\n",
    "                                [4,2*np.sqrt(3)],[5,np.sqrt(3)],[6,0],\\\n",
    "                                [5,0],[4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "\n",
    "    for contour in original_contours:\n",
    "        _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        max_piece_index = np.argmax([len(x) for x in contours_opencv])\n",
    "\n",
    "        square_match = cv2.matchShapes(contours_opencv[max_piece_index], square_sample, 1, 0)\n",
    "        triangle_match = cv2.matchShapes(contours_opencv[max_piece_index], triangle_sample, 1, 0)\n",
    "\n",
    "        shape_match.append([square_match, triangle_match])\n",
    "\n",
    "    shape_match\n",
    "\n",
    "    clssified_blobs = []\n",
    "    for blob_index in range(len(contours)):\n",
    "        # considered to be circule\n",
    "        if shapes[blob_index] > 10 or (shapes[blob_index] >= 10 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "            clssified_blobs.append('circle')\n",
    "        # considered to be triangle\n",
    "        elif (shape_match[blob_index][1] < 2 and shape_match[blob_index][0] * 3 < shape_match[blob_index][1]) or (shapes[blob_index] >= 6 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "            clssified_blobs.append('triangle')\n",
    "        # considered to be square\n",
    "        else:\n",
    "            clssified_blobs.append('square')\n",
    "\n",
    "    clssified_blobs\n",
    "\n",
    "    relevant_annotations = [x for x in annotation_list if str(case) in x]\n",
    "\n",
    "    evaluation = {'triangle_total': 0, 'triangle_true_predict': 0,\\\n",
    "                  'square_total': 0, 'square_true_predict': 0,\\\n",
    "                  'circle_total': 0, 'circle_true_predict': 0}\n",
    "\n",
    "    for file in relevant_annotations:\n",
    "        if 'triangle' in file:\n",
    "            evaluation['triangle_total'] += 1\n",
    "        elif 'square' in file:\n",
    "            evaluation['square_total'] += 1\n",
    "        elif 'circle' in file:\n",
    "            evaluation['circle_total'] += 1\n",
    "\n",
    "        matched_index = -1\n",
    "        verify_img = cv2.imread(file)\n",
    "        verify_img = cv2.cvtColor(verify_img, cv2.COLOR_BGR2GRAY)\n",
    "        for contour_index in range(len(original_contours)):\n",
    "            if matched_index != -1:\n",
    "                break\n",
    "            for x in range(original_contours[contour_index].shape[0]):\n",
    "                for y in range(original_contours[contour_index].shape[1]):\n",
    "                    if original_contours[contour_index][x][y] != 0 and verify_img[x][y] != 0:\n",
    "                        matched_index = contour_index\n",
    "                        break\n",
    "\n",
    "        if clssified_blobs[matched_index] in file:\n",
    "            evaluation[clssified_blobs[matched_index] + '_true_predict'] += 1\n",
    "\n",
    "    evaluation\n",
    "\n",
    "    precision = (evaluation['triangle_true_predict'] + evaluation['square_true_predict'] + evaluation['circle_true_predict']) / \\\n",
    "                (evaluation['triangle_total'] + evaluation['square_total'] + evaluation['circle_total'])\n",
    "\n",
    "    print('precision:', np.ceil(precision * 100), '%')\n",
    "\n",
    "    txt_file = open(output_file + '/Evaluation.txt','w')\n",
    "    txt_file.write(str(evaluation))\n",
    "    txt_file.write('\\n')\n",
    "    txt_file.write('precision:' + str(np.ceil(precision * 100)) + '%')\n",
    "    txt_file.close()\n",
    "    \n",
    "    for key in overall_evaluation.keys():\n",
    "        overall_evaluation[key] += evaluation[key]\n",
    "\n",
    "precision = (overall_evaluation['triangle_true_predict'] + overall_evaluation['square_true_predict'] + overall_evaluation['circle_true_predict']) / \\\n",
    "                (overall_evaluation['triangle_total'] + overall_evaluation['square_total'] + overall_evaluation['circle_total'])\n",
    "\n",
    "txt_file = open('./output/Overall_Evaluation.txt','w')\n",
    "txt_file.write(str(overall_evaluation))\n",
    "txt_file.write('\\n')\n",
    "txt_file.write('precision:' + str(np.ceil(precision * 100)) + '%')\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
