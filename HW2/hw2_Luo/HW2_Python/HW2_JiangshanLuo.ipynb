{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS585 Assignment 2 Programming Part\n",
    "### Author: Jiangshan Luo\n",
    "### Uni ID: U89971259"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue;\"> In this notebook, I will present the method for my Python program to handle each single task in the HW2 requirement by processing an image individually and show the result for each stage.</span> \n",
    "### <span style=\"color:blue;\"> The real program (process all images) is shown in the last cell which is only the merged version of the cells above. </span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from os import listdir, makedirs\n",
    "from os.path import isfile, join, abspath, exists\n",
    "from collections import Counter\n",
    "from IPython.display import Image as print_image\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "data_path = abspath('./shapes_dataset/shapes_train2018')\n",
    "data_list = [join(data_path, file) for file in listdir(data_path) if isfile(join(data_path, file)) and 'jpeg' in file]\n",
    "annotation_path = abspath('./shapes_dataset/annotations')\n",
    "annotation_list = [join(annotation_path, file) for file in listdir(annotation_path) if isfile(join(annotation_path, file)) and 'png' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_case = 1048\n",
    "output_file = './output/' + str(test_case)\n",
    "if not exists(output_file):\n",
    "    makedirs(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Determine the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The background color is 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:22: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nmErby2Kh2IglVZFIaJwJFZXRTXwRRRRX/9k=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(data_list[test_case - 1000])\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# medianBlur -> remove the noise\n",
    "img_gray = cv2.medianBlur(img_gray,5)\n",
    "\n",
    "# find the background color\n",
    "boarder_pixel = []\n",
    "for x in range(img_gray.shape[0]):\n",
    "    for y in range(img_gray.shape[1]):\n",
    "        if x == 0 or y == 0:\n",
    "            boarder_pixel.append(img_gray[x][y])\n",
    "            \n",
    "# assume background color is the pixel value that has the maxi|mum frequency\n",
    "background_color, frequency = Counter(boarder_pixel).most_common(1)[0]\n",
    "print('The background color is', background_color)\n",
    "\n",
    "img_withoutBG = img_gray.copy()\n",
    "for x in range(img_withoutBG.shape[0]):\n",
    "    for y in range(img_withoutBG.shape[1]):\n",
    "        if(np.abs(img_withoutBG[x][y] - background_color)) < 10:\n",
    "            img_withoutBG[x][y] = 0\n",
    "            '''# Floodfill\n",
    "            h, w = img_gray.shape[:2]\n",
    "            mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "            cv2.floodFill(img_gray, mask, (x, y), 0)\n",
    "            cv2.imwrite(str(count)+'.jpeg',img_gray)\n",
    "            count = count + 1'''\n",
    "     \n",
    "cv2.imwrite(output_file + '/img_withoutBG.jpeg',img_withoutBG)\n",
    "print_image(output_file + '/img_withoutBG.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Label every shape blob based on color\n",
    "### <span style=\"color:blue;\">2.1 remove the noises <span/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# test remove_surrounding_noise\\ntest_img = img_noNoise.copy()\\nremove_surrounding_noise(test_img, blob_colors)\\ncv2.imwrite('2.jpeg',test_img)\\n\\nblob_detector=[]\\nfor x in range(test_img.shape[0]):\\n    for y in range(test_img.shape[1]):\\n        if(test_img[x][y] != 0):\\n            blob_detector.append(test_img[x][y])\\nCounter(blob_detector)\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "bfs(img, flag_img, seed_point=[0,0])\n",
    "\n",
    "    use BFS to find the size of each blob\n",
    "    input: \n",
    "        - img: src image\n",
    "        - flag_img: boolean map used to mark the blob\n",
    "        - seed_point: start searching point\n",
    "    output:\n",
    "        - count: size of the blob\n",
    "'''\n",
    "def bfs(img, flag_img, seed_point=[0,0]):\n",
    "    count = 1\n",
    "    matrix = [[1,0],[-1,0],[0,1],[0,-1]]\n",
    "    neighbor = [0,0]\n",
    "    flag_img[seed_point[0]][seed_point[1]] = 1\n",
    "    \n",
    "    queue = [seed_point]\n",
    "    \n",
    "    while len(queue) > 0:\n",
    "        # enqueue and dequeue\n",
    "        current_point = queue[0]\n",
    "        del queue[0]\n",
    "        \n",
    "        for element in matrix:\n",
    "            neighbor[0] = current_point[0] + element[0]\n",
    "            neighbor[1] = current_point[1] + element[1]\n",
    "            if neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1]:\n",
    "                if np.abs(img[neighbor[0]][neighbor[1]] - img[seed_point[0]][seed_point[1]]) < 10 and flag_img[neighbor[0]][neighbor[1]] == 0:\n",
    "                    count = count + 1\n",
    "                    flag_img[neighbor[0]][neighbor[1]] = 1\n",
    "                    queue.append(neighbor.copy())\n",
    "    \n",
    "    return count\n",
    "\n",
    "'''# test bfs\n",
    "flag = np.zeros_like(img_withoutBG)\n",
    "bfs(img_withoutBG, flag)'''\n",
    "\n",
    "'''\n",
    "remove_surrounding_noise(img, blob_color = [])\n",
    "\n",
    "    remove noise with colors other than blobs and small size blobs\n",
    "    input:\n",
    "        - img: src image\n",
    "        - blob_color: the colors of the blobs\n",
    "'''\n",
    "def remove_surrounding_noise(img, blob_color = []):\n",
    "    search_map = np.zeros_like(img)\n",
    "    \n",
    "    # remove noise with the blob colors\n",
    "    for x in range(img.shape[0]):\n",
    "        for y in range(img.shape[1]):\n",
    "            if img[x][y] in blob_color:\n",
    "                if search_map[x][y] == 0:\n",
    "                    # find the size of the image\n",
    "                    flag_map = np.zeros_like(img)\n",
    "                    blob_size = bfs(img, flag_map, [x,y])\n",
    "\n",
    "                    # update the search map\n",
    "                    search_map += flag_map\n",
    "\n",
    "                    # remove the blobs which size < 300 pixels\n",
    "                    if blob_size < 300:\n",
    "                        for x_1 in range(flag_map.shape[0]):\n",
    "                            for y_1 in range(flag_map.shape[1]):\n",
    "                                if(flag_map[x_1][y_1] == 1):\n",
    "                                    img[x_1][y_1] = 0\n",
    "            # remove noise with colors other than blobs\n",
    "            else:\n",
    "                img[x][y] = 0\n",
    "\n",
    "'''# test remove_surrounding_noise\n",
    "test_img = img_noNoise.copy()\n",
    "remove_surrounding_noise(test_img, blob_colors)\n",
    "cv2.imwrite('2.jpeg',test_img)\n",
    "\n",
    "blob_detector=[]\n",
    "for x in range(test_img.shape[0]):\n",
    "    for y in range(test_img.shape[1]):\n",
    "        if(test_img[x][y] != 0):\n",
    "            blob_detector.append(test_img[x][y])\n",
    "Counter(blob_detector)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue;\">2.2 label blobs <span/>\n",
    "every unique grayscale color value remain in the image represent a blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\n7Fx5lRRRX//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob_detector = []\n",
    "for x in range(img_withoutBG.shape[0]):\n",
    "    for y in range(img_withoutBG.shape[1]):\n",
    "        if(img_withoutBG[x][y] != 0):\n",
    "            blob_detector.append(img_withoutBG[x][y])\n",
    "\n",
    "# assume blobs have more than 500 pixels\n",
    "counter_keys = list(Counter(blob_detector).keys())\n",
    "blob_colors = [x for x in counter_keys if Counter(blob_detector)[x] > 300]\n",
    "\n",
    "img_noNoise = img_withoutBG.copy()\n",
    "\n",
    "# remove the noise (non-blobs-color pixels and small size blobs)\n",
    "remove_surrounding_noise(img_noNoise, blob_colors)\n",
    "\n",
    "# medianBlur -> remove the noise\n",
    "img_noNoise = cv2.medianBlur(img_noNoise,5)\n",
    "\n",
    "'''#recognize the shapes\n",
    "for x in range(img_noNoise.shape[0]):\n",
    "    for y in range(img_noNoise.shape[1]):\n",
    "        if(img_noNoise[x][y] in blob_colors):\n",
    "            img_noNoise[x][y] = 255'''\n",
    "\n",
    "obj_num = 1\n",
    "for color in blob_colors:\n",
    "    blob_image = np.zeros_like(img_noNoise)\n",
    "    for x in range(img_noNoise.shape[0]):\n",
    "        for y in range(img_noNoise.shape[1]):\n",
    "            if img_noNoise[x][y] == color:\n",
    "                blob_image[x][y] = 255\n",
    "    cv2.imwrite(output_file + '/blob_' + str(obj_num) + '.jpeg', blob_image)\n",
    "    obj_num += 1\n",
    "\n",
    "cv2.imwrite(output_file + '/img_noNoise.jpeg',img_noNoise)\n",
    "print_image(output_file + '/img_noNoise.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF\nBgYGBwkIBgcJBwYGCAsICQoKCgoKBggLDAsKDAkKCgr/wAALCACAAIABAREA/8QAHwAAAQUBAQEB\nAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1Fh\nByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZ\nWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXG\nx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/AP5/6KKKKKKKKK/X7/gy\np/5Sm+Pv+zf9V/8AT5odf0/UUUUV/AHRRRRRRRRRX6/f8GVP/KU3x9/2b/qv/p80Ov6fqKKKK/gD\nooooooooor9fv+DKn/lKb4+/7N/1X/0+aHX9P1FFFFfwB0UUUUUUUUV+z3/Bkv8AC3x3q/7fXxX+\nNen6F5nhjw/8H20TV9T+1RD7Pf6hqtjPZw+WWEj+ZFpl825VKr5GGKl0Df0vUUUUV/AHRRRRRRRR\nRX9Zv/BpN4Z+DWg/8EW/B+qfDC5099b1rxh4gvfiMtlqxuZI9ZW+e3iWeMyN9ll/syDSyIQEBjaK\nXaTMXf8AS+iiiiv4A6KKKKKKKKK+7/8Ag3m/4Kp6d/wSw/bzs/GPxW8R6ha/Cfx1p7aF8SobSC4u\nltY8l7PU1tYpVEkttcYBfZNIlrcXqwxPJKoP9Xus/tu/sX+HPg1pP7RniH9rv4X2Hw91/UGsNC8d\n3vj/AE6LRtRulMytbwXrTCCaUG2uAURywMEox8jY9Qooor+AOiiiiiiiiiiiiiiiiiiiiiiiiiii\niiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiii\niiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiiv//Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for color in blob_colors:\n",
    "        blob_image = np.zeros_like(img_noNoise)\n",
    "        for x in range(img_noNoise.shape[0]):\n",
    "            for y in range(img_noNoise.shape[1]):\n",
    "                if img_noNoise[x][y] == color:\n",
    "                    blob_image[x][y] = 255\n",
    "        cv2.imwrite(output_file + '/blob_' + str(obj_num) + '.jpeg', blob_image)\n",
    "\n",
    "print_image(output_file + '/blob_1.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nRRRRRRRRRRRRRRRRRRRRRRX/2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_image(output_file + '/blob_2.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\n/bXE5meC1t0/7ZxmeVpbiRLeBZZpfKQjwCiiiv/Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_image(output_file + '/blob_3.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Implement the boundary following algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# test boundary_following\\ntest_contour = boundary_following(img_noNoise, blob_colors)\\ncv2.imwrite('3.jpeg', test_contour[0])\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "boundary_following(img, blob_color)\n",
    "    \n",
    "    implementation of the boundary following algorithm\n",
    "    input: \n",
    "        - img: src image\n",
    "        - blob_color: the colors of the blobs\n",
    "    output:\n",
    "        - contour_map: a list of contour images\n",
    "'''\n",
    "def boundary_following(img, blob_color):\n",
    "    contour_map = []\n",
    "    search_map = np.zeros_like(img)\n",
    "    # clockwise start from the west\n",
    "    clockwise_matrix = [[0,-1],[-1,-1],[-1,0],[-1,1],[0,1],[1,1],[1,0],[1,-1]]\n",
    "    # boundary pixel outside R\n",
    "    b = [0,0]\n",
    "    # current pixel inside object on boundary\n",
    "    c = [0,0]\n",
    "    \n",
    "    for x in range(img.shape[0]):\n",
    "        for y in range(img.shape[1]):\n",
    "            # find the start pixel\n",
    "            if img[x][y] in blob_color and search_map[x][y] == 0 and bfs(img, search_map, [x,y]) > 300:\n",
    "                # use bfs() to update the search_map -> make sure every blob only be computed once\n",
    "                pixel_color = img[x][y]\n",
    "                \n",
    "                contour = np.zeros_like(img)\n",
    "                c = [x,y]\n",
    "                b[0] = c[0] + clockwise_matrix[0][0]\n",
    "                b[1] = c[1] + clockwise_matrix[0][1]\n",
    "                \n",
    "                finish_flag = False\n",
    "                while not finish_flag:\n",
    "                    # find next neighbor (b is supposed to start from the west neighbor outside R)\n",
    "                    neighbor = b.copy()\n",
    "                    start_index = clockwise_matrix.index([neighbor[0] - c[0], neighbor[1] - c[1]])\n",
    "                    \n",
    "                    for loop_time in range(8):\n",
    "                        neighbor[0] = c[0] + clockwise_matrix[(start_index + loop_time) % 8][0]\n",
    "                        neighbor[1] = c[1] + clockwise_matrix[(start_index + loop_time) % 8][1]\n",
    "                        \n",
    "                        # find the first neighbor inside R, update b and c\n",
    "                        if neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1] \\\n",
    "                        and img[neighbor[0]][neighbor[1]] == pixel_color:\n",
    "                                c = neighbor.copy()\n",
    "                                b = last_neighbor.copy()\n",
    "                                contour[neighbor[0]][neighbor[1]] = 255\n",
    "                                \n",
    "                                # finish\n",
    "                                if neighbor == [x,y]:\n",
    "                                    finish_flag = True\n",
    "                                \n",
    "                                break\n",
    "                        else:\n",
    "                            last_neighbor = neighbor.copy()\n",
    "                \n",
    "                contour_map.append(contour.copy())\n",
    "    \n",
    "    return np.array(contour_map)\n",
    "\n",
    "'''# test boundary_following\n",
    "test_contour = boundary_following(img_noNoise, blob_colors)\n",
    "cv2.imwrite('3.jpeg', test_contour[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contours = boundary_following(img_noNoise, blob_colors)\n",
    "\n",
    "merged_contour = np.zeros_like(img_noNoise)\n",
    "for contour in contours:\n",
    "    merged_contour += contour\n",
    "\n",
    "cv2.imwrite(output_file + '/boundary_following.jpeg', merged_contour)\n",
    "print_image(output_file + '/boundary_following.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compare the boundary following algorithm with cv2.findContours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nJFp2laSkvlq7LGgMl3ctFBbQyX95JcX1ylpbi4uZzCjDz+iiiv/Z\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, contours_opencv, hierarchy = cv2.findContours(img_noNoise, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "image_background = np.zeros_like(img_noNoise)\n",
    "# contourIdx=-1 draw all contours\n",
    "opencv_drawContours_result = cv2.drawContours(image_background, contours_opencv, contourIdx=-1, color=255, thickness=1)\n",
    "\n",
    "cv2.imwrite(output_file + '/opencv_drawContours_result.jpeg',opencv_drawContours_result)\n",
    "print_image(output_file + '/opencv_drawContours_result.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Classify boundary pixels (background/another blob/image boundary)\n",
    "use the contours and blob colors gained previously to classify the boundary pixel:\n",
    "\n",
    "    - against background: have background neighbor pixel\n",
    "    - against image boundary: image boundary pixel\n",
    "    - against another blob: have neighbor pixel that belongs to one of the other blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAIBAQEBAQIBAQECAgICAgQDAgICAgUEBAMEBgUGBgYF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\nFlp1hbLFBAGwCQBy7kKimWQtI4jTe7bRWXRRRX//2Q==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mark three categories with grayscale value: 80, 160, 240\n",
    "classified_contours = []\n",
    "N4_neighbor = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "neighbor = [0,0]\n",
    "\n",
    "for contour in contours:\n",
    "    classified_contour = contour.copy()\n",
    "    \n",
    "    for x in range(classified_contour.shape[0]):\n",
    "        for y in range(classified_contour.shape[1]):\n",
    "            # classify each pixel in the contour\n",
    "            if classified_contour[x][y] == 255:\n",
    "                is_background = False\n",
    "                is_boundary = False\n",
    "                \n",
    "                # find the characteristics of its neighbors\n",
    "                for element in N4_neighbor:\n",
    "                    neighbor[0] = x + element[0]\n",
    "                    neighbor[1] = y + element[1]\n",
    "                    \n",
    "                    # iamge boundary\n",
    "                    if not (neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1]):\n",
    "                        is_boundary = True\n",
    "                        break\n",
    "                    # background\n",
    "                    elif img_noNoise[neighbor[0]][neighbor[1]] == 0:\n",
    "                        is_background = True\n",
    "                        break\n",
    "                \n",
    "                if(is_background):\n",
    "                    classified_contour[x][y] = 80\n",
    "                elif(is_boundary):\n",
    "                    classified_contour[x][y] = 160\n",
    "                # others belongs to contour against other blobs\n",
    "                else:\n",
    "                    classified_contour[x][y] = 240\n",
    "\n",
    "    classified_contours.append(classified_contour)\n",
    "\n",
    "# classified_contours contains classification info of each contour\n",
    "merged_classified_contour = np.zeros_like(img_noNoise)\n",
    "for contour in classified_contours:\n",
    "    merged_classified_contour += contour\n",
    "    \n",
    "cv2.imwrite(output_file + '/merged_classified_contour.jpeg',merged_classified_contour)\n",
    "print_image(output_file + '/merged_classified_contour.jpeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. Blob shape recognition\n",
    "\n",
    "use different attributes of the blobs to recognize their shape. For this task, part of the blob contours will be used (those against the background) because they are not influenced by other factors and are the original shape of the blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### centorids and compactness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22.936781609195403, 106.35057471264368], [70.18300653594771, 76.7124183006536], [104.08982035928143, 61.34730538922156]]\n",
      "[14.60492040520984, 15.731854838709678, 15.597874720357941]\n"
     ]
    }
   ],
   "source": [
    "# find centorids of blobs in order to determine the positions of them in the annotation file\n",
    "centorids = []\n",
    "compactness = []\n",
    "\n",
    "for contour in classified_contours:\n",
    "    sum_contour = [0,0]\n",
    "    pixel_count = 0\n",
    "    blob_area = 0\n",
    "    compute_area= False\n",
    "    \n",
    "    for x in range(contour.shape[0]):\n",
    "        for y in range(contour.shape[1]):\n",
    "            if contour[x][y] != 0:\n",
    "                sum_contour[0] += x\n",
    "                sum_contour[1] += y\n",
    "                pixel_count += 1\n",
    "                \n",
    "                if not compute_area:\n",
    "                    blob_area = bfs(img_noNoise, np.zeros_like(img_noNoise), [x,y])\n",
    "                    compute_area = True\n",
    "    \n",
    "    centorids.append([sum_contour[0] / pixel_count, sum_contour[1] / pixel_count])\n",
    "    compactness.append(pixel_count ** 2 / blob_area)\n",
    "\n",
    "print(centorids)\n",
    "print(compactness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### approxPolyDP guess the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 12, 11]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordered contour\n",
    "original_contours = classified_contours.copy()\n",
    "for index in range(len(original_contours)):\n",
    "    for x in range(original_contours[index].shape[0]):\n",
    "        for y in range(original_contours[index].shape[1]):\n",
    "            if original_contours[index][x][y] != 80:\n",
    "                original_contours[index][x][y] = 0\n",
    "\n",
    "shapes = []\n",
    "for contour in original_contours:\n",
    "    shape = 0\n",
    "    _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for cnt_piece in contours_opencv:\n",
    "        shape += len(cv2.approxPolyDP(np.array(cnt_piece), 10, closed=False))\n",
    "    \n",
    "    shapes.append(shape)\n",
    "    \n",
    "shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### matchShapes compute the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.7976931348623157e+308, 1.7976931348623157e+308],\n",
       " [0.14067220947362946, 0.4225515720969898],\n",
       " [1.7976931348623157e+308, 1.7976931348623157e+308]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape_match = []\n",
    "square_sample = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],\\\n",
    "                          [1,5],[2,5],[3,5],[4,5],[5,5],\\\n",
    "                          [5,4],[5,3],[5,2],[5,1],[5,0],\\\n",
    "                          [4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "triangle_sample = np.array([[0,0],[1,np.sqrt(3)],[2,2*np.sqrt(3)],[3,3*np.sqrt(3)],\\\n",
    "                            [4,2*np.sqrt(3)],[5,np.sqrt(3)],[6,0],\\\n",
    "                            [5,0],[4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "\n",
    "for contour in original_contours:\n",
    "    _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    max_piece_index = np.argmax([len(x) for x in contours_opencv])\n",
    "    \n",
    "    square_match = cv2.matchShapes(contours_opencv[max_piece_index], square_sample, 1, 0)\n",
    "    triangle_match = cv2.matchShapes(contours_opencv[max_piece_index], triangle_sample, 1, 0)\n",
    "    \n",
    "    shape_match.append([square_match, triangle_match])\n",
    "\n",
    "shape_match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion of the recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['square', 'circle', 'circle']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clssified_blobs = []\n",
    "for blob_index in range(len(contours)):\n",
    "    # considered to be circule\n",
    "    if shapes[blob_index] > 10 or (shapes[blob_index] >= 10 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "        clssified_blobs.append('circle')\n",
    "    # considered to be triangle\n",
    "    elif (shape_match[blob_index][1] < 2 and shape_match[blob_index][0] * 3 < shape_match[blob_index][1]) or (shapes[blob_index] >= 6 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "        clssified_blobs.append('triangle')\n",
    "    # considered to be square\n",
    "    else:\n",
    "        clssified_blobs.append('square')\n",
    "\n",
    "clssified_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'circle_total': 1,\n",
       " 'circle_true_predict': 1,\n",
       " 'square_total': 1,\n",
       " 'square_true_predict': 1,\n",
       " 'triangle_total': 1,\n",
       " 'triangle_true_predict': 0}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_annotations = [x for x in annotation_list if str(test_case) in x and 'crowd' not in x]\n",
    "\n",
    "evaluation = {'triangle_total': 0, 'triangle_true_predict': 0,\\\n",
    "              'square_total': 0, 'square_true_predict': 0,\\\n",
    "              'circle_total': 0, 'circle_true_predict': 0}\n",
    "\n",
    "for file in relevant_annotations:\n",
    "    if 'triangle' in file:\n",
    "        evaluation['triangle_total'] += 1\n",
    "    elif 'square' in file:\n",
    "        evaluation['square_total'] += 1\n",
    "    elif 'circle' in file:\n",
    "        evaluation['circle_total'] += 1\n",
    "    \n",
    "    matched_index = -1\n",
    "    verify_img = cv2.imread(file)\n",
    "    verify_img = cv2.cvtColor(verify_img, cv2.COLOR_BGR2GRAY)\n",
    "    for contour_index in range(len(original_contours)):\n",
    "        if matched_index != -1:\n",
    "            break\n",
    "        for x in range(original_contours[contour_index].shape[0]):\n",
    "            for y in range(original_contours[contour_index].shape[1]):\n",
    "                if original_contours[contour_index][x][y] != 0 and verify_img[x][y] != 0:\n",
    "                    matched_index = contour_index\n",
    "                    break\n",
    "    \n",
    "    if clssified_blobs[matched_index] in file:\n",
    "        evaluation[clssified_blobs[matched_index] + '_true_predict'] += 1\n",
    "\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 67.0 %\n"
     ]
    }
   ],
   "source": [
    "precision = (evaluation['triangle_true_predict'] + evaluation['square_true_predict'] + evaluation['circle_true_predict']) / \\\n",
    "            (evaluation['triangle_total'] + evaluation['square_total'] + evaluation['circle_total'])\n",
    "\n",
    "print('precision:', np.ceil(precision * 100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_file = open(output_file + '/Evaluation.txt','w')\n",
    "txt_file.write(str(evaluation))\n",
    "txt_file.write('\\n')\n",
    "txt_file.write('precision:' + str(np.ceil(precision * 100)) + '%')\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process all images (merge the code above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The background color is 178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: overflow encountered in ubyte_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35.004347826086956, 90.25652173913043]]\n",
      "[14.308899107384367]\n",
      "precision: 0.0 %\n",
      "The background color is 139\n",
      "[[27.11464968152866, 77.97452229299363], [34.05223880597015, 34.291044776119406], [85.5618556701031, 23.5], [99.3953488372093, 100.86976744186046]]\n",
      "[9.883319967923015, 12.148849797023004, 14.893549663632767, 15.052100293064148]\n",
      "precision: 75.0 %\n",
      "The background color is 40\n",
      "[[19.98095238095238, 26.723809523809525], [56.48951048951049, 11.468531468531468], [54.91379310344828, 33.775862068965516], [103.92361111111111, 30.930555555555557]]\n",
      "[12.022900763358779, 61.408408408408405, 10.186222558667676, 13.750663129973475]\n",
      "precision: 0.0 %\n",
      "The background color is 86\n",
      "[[48.71508379888268, 40.11731843575419], [96.4493670886076, 26.9873417721519]]\n",
      "[17.366395663956638, 15.90063694267516]\n",
      "precision: 100.0 %\n",
      "The background color is 127\n",
      "[[26.048387096774192, 66.13709677419355], [78.73493975903614, 84.26506024096386]]\n",
      "[9.707070707070708, 10.160766961651918]\n",
      "precision: 50.0 %\n",
      "The background color is 191\n",
      "[[56.845360824742265, 23.50515463917526], [81.76190476190476, 66.64285714285714], [96.81547619047619, 26.339285714285715]]\n",
      "[16.13893653516295, 11.396984924623116, 11.191118160190324]\n",
      "precision: 34.0 %\n",
      "The background color is 211\n",
      "[[58.52212389380531, 83.30973451327434], [89.56223175965665, 45.31330472103004]]\n",
      "[14.778935185185185, 15.418631070718545]\n",
      "precision: 50.0 %\n",
      "The background color is 125\n",
      "[[70.98780487804878, 68.6951219512195], [105.19402985074628, 37.55223880597015]]\n",
      "[10.651881188118812, 13.510910458991724]\n",
      "precision: 100.0 %\n",
      "The background color is 136\n",
      "[[74.65873015873017, 76.33333333333333]]\n",
      "[14.341463414634147]\n",
      "precision: 100.0 %\n",
      "The background color is 187\n",
      "[[35.125786163522015, 42.125786163522015]]\n",
      "[13.829868708971553]\n",
      "precision: 0.0 %\n",
      "The background color is 63\n",
      "[[60.0, 39.015306122448976]]\n",
      "[13.878612716763005]\n",
      "precision: 0.0 %\n",
      "The background color is 179\n",
      "[[24.811023622047244, 48.22834645669291], [102.63414634146342, 97.37073170731708]]\n",
      "[10.144025157232704, 14.792326645547343]\n",
      "precision: 0.0 %\n",
      "The background color is 154\n",
      "[[48.074074074074076, 102.74691358024691], [33.258278145695364, 26.543046357615893]]\n",
      "[15.056798623063683, 6.87605548854041]\n",
      "precision: 25.0 %\n",
      "The background color is 155\n",
      "[[76.0042372881356, 52.24576271186441]]\n",
      "[14.332475553268143]\n",
      "precision: 0.0 %\n",
      "The background color is 172\n",
      "[[81.53254437869822, 26.828402366863905], [97.38297872340425, 97.88085106382978]]\n",
      "[10.546898079763663, 15.117711470024638]\n",
      "precision: 50.0 %\n",
      "The background color is 123\n",
      "[[40.7037037037037, 57.03086419753087], [44.094202898550726, 105.68840579710145], [70.12556053811659, 27.358744394618835], [82.54, 67.1]]\n",
      "[20.632075471698112, 13.681034482758621, 14.844477611940299, 14.771048744460856]\n",
      "precision: 75.0 %\n",
      "The background color is 74\n",
      "[[53.68518518518518, 35.96296296296296]]\n",
      "[14.3960504662644]\n",
      "precision: 100.0 %\n",
      "The background color is 208\n",
      "[[37.25, 50.15217391304348], [78.84545454545454, 69.24545454545455], [102.6086956521739, 43.46376811594203]]\n",
      "[14.382327952421411, 10.950226244343892, 12.603573792190602]\n",
      "precision: 34.0 %\n",
      "The background color is 108\n",
      "[[62.07738095238095, 55.625], [48.90816326530612, 20.43877551020408]]\n",
      "[14.570986060918948, 16.50171821305842]\n",
      "precision: 50.0 %\n",
      "The background color is 108\n",
      "[[32.098591549295776, 73.47887323943662], [88.88157894736842, 77.92763157894737]]\n",
      "[14.180028129395218, 10.053959965187119]\n",
      "precision: 100.0 %\n",
      "The background color is 99\n",
      "[[34.91095890410959, 105.1986301369863], [51.15483870967742, 32.66451612903226], [88.08035714285714, 84.09821428571429], [86.73195876288659, 38.577319587628864]]\n",
      "[10.825799898425597, 12.986486486486486, 10.462051709758132, 9409.0]\n",
      "precision: 50.0 %\n",
      "The background color is 157\n",
      "[[75.93167701863354, 56.577639751552795]]\n",
      "[9.561416451493914]\n",
      "precision: 100.0 %\n",
      "The background color is 148\n",
      "[[46.85616438356164, 68.1027397260274], [52.588235294117645, 25.96323529411765], [104.00526315789473, 71.0]]\n",
      "[11.344332091538051, 12.642515379357485, 14.807219031993437]\n",
      "precision: 100.0 %\n",
      "The background color is 55\n",
      "[[32.380116959064324, 32.0], [59.75229357798165, 90.4954128440367]]\n",
      "[11.65444400159426, 13.65632183908046]\n",
      "precision: 100.0 %\n",
      "The background color is 189\n",
      "[[72.46982758620689, 69.38793103448276], [118.01785714285714, 93.22321428571429]]\n",
      "[14.661944974121493, 14.48498845265589]\n",
      "precision: 50.0 %\n",
      "The background color is 148\n",
      "[[56.223076923076924, 71.99230769230769], [106.82098765432099, 90.25308641975309]]\n",
      "[11.089238845144356, 14.356673960612692]\n",
      "precision: 0.0 %\n",
      "The background color is 54\n",
      "[[93.8586387434555, 41.1413612565445]]\n",
      "[14.134444013948082]\n",
      "precision: 0.0 %\n",
      "The background color is 217\n",
      "[[47.541935483870965, 45.07741935483871], [63.64748201438849, 77.41726618705036], [81.4090909090909, 101.17272727272727], [104.375, 38.07142857142857]]\n",
      "[11.753913894324853, 16.18174204355109, 5.077633235417541, 13.546436285097192]\n",
      "precision: 34.0 %\n",
      "The background color is 205\n",
      "[[50.21232876712329, 27.102739726027398], [64.51322751322752, 62.86243386243386]]\n",
      "[15.074964639321076, 11.922897196261681]\n",
      "precision: 100.0 %\n",
      "The background color is 189\n",
      "[[45.229007633587784, 21.244274809160306]]\n",
      "[15.119823788546256]\n",
      "precision: 100.0 %\n",
      "The background color is 98\n",
      "[[83.25, 28.978813559322035]]\n",
      "[14.59538784067086]\n",
      "precision: 0.0 %\n",
      "The background color is 202\n",
      "[[37.85314685314685, 80.44055944055944], [75.43612334801762, 55.12334801762115]]\n",
      "[19.549713193116634, 14.281873614190687]\n",
      "precision: 50.0 %\n",
      "The background color is 177\n",
      "[[36.87428571428571, 37.38285714285714], [43.73394495412844, 94.8440366972477]]\n",
      "[14.398213446168311, 12.900108577633008]\n",
      "precision: 100.0 %\n",
      "The background color is 159\n",
      "[[105.81018518518519, 37.88425925925926], [98.23684210526316, 62.51754385964912]]\n",
      "[24.174093264248704, 11.511071744906998]\n",
      "precision: 50.0 %\n",
      "The background color is 142\n",
      "[[35.77514792899408, 90.72189349112426], [95.02564102564102, 19.854700854700855]]\n",
      "[14.852314092563702, 14.394321766561514]\n",
      "precision: 100.0 %\n",
      "The background color is 163\n",
      "[[45.717557251908396, 30.610687022900763], [59.14728682170543, 87.62790697674419]]\n",
      "[15.772977941176471, 16.109390125847046]\n",
      "precision: 50.0 %\n",
      "The background color is 180\n",
      "[[33.120253164556964, 105.35443037974683], [65.88397790055248, 76.17127071823204]]\n",
      "[11.955938697318008, 15.818928054080155]\n",
      "precision: 100.0 %\n",
      "The background color is 168\n",
      "[[30.213740458015266, 88.45038167938931], [79.86473429951691, 101.40096618357488], [89.95121951219512, 27.359756097560975]]\n",
      "[14.642491467576791, 14.544806517311608, 10.635033610122578]\n",
      "precision: 34.0 %\n",
      "The background color is 166\n",
      "[[39.24193548387097, 103.74731182795699], [101.96875, 34.3203125], [105.456, 71.736]]\n",
      "[14.860824742268042, 13.202256244963738, 14.589169000933706]\n",
      "precision: 50.0 %\n",
      "The background color is 93\n",
      "[[86.41059602649007, 97.64238410596026]]\n",
      "[14.18855009334163]\n",
      "precision: 100.0 %\n",
      "The background color is 65\n",
      "[[33.298780487804876, 39.5]]\n",
      "[13.799897383273473]\n",
      "precision: 0.0 %\n",
      "The background color is 34\n",
      "[[67.26470588235294, 89.96470588235294], [81.6, 49.4]]\n",
      "[14.118221787982414, 16.273219814241486]\n",
      "precision: 50.0 %\n",
      "The background color is 193\n",
      "[[44.642857142857146, 50.36507936507937]]\n",
      "[14.302702702702703]\n",
      "precision: 100.0 %\n",
      "The background color is 144\n",
      "[[27.91549295774648, 31.274647887323944], [70.91869918699187, 35.829268292682926], [105.97849462365592, 45.215053763440864]]\n",
      "[10.771367521367521, 10.498959056210964, 11.962655601659751]\n",
      "precision: 67.0 %\n",
      "The background color is 161\n",
      "[[96.72972972972973, 61.263513513513516]]\n",
      "[13.380574221136225]\n",
      "precision: 0.0 %\n",
      "The background color is 86\n",
      "[[45.88510638297873, 84.40425531914893]]\n",
      "[14.258972372837594]\n",
      "precision: 0.0 %\n",
      "The background color is 115\n",
      "[[88.92307692307692, 45.287179487179486]]\n",
      "[18.307655272026963]\n",
      "precision: 100.0 %\n",
      "The background color is 56\n",
      "[[78.80838323353294, 86.88622754491018]]\n",
      "[10.260853568800588]\n",
      "precision: 100.0 %\n",
      "The background color is 43\n",
      "[[22.936781609195403, 106.35057471264368], [70.18300653594771, 76.7124183006536], [104.08982035928143, 61.34730538922156]]\n",
      "[14.60492040520984, 15.731854838709678, 15.597874720357941]\n",
      "precision: 67.0 %\n",
      "The background color is 96\n",
      "[[68.96428571428571, 69.44642857142857]]\n",
      "[10.58565400843882]\n",
      "precision: 0.0 %\n",
      "The background color is 179\n",
      "[[43.629629629629626, 98.26851851851852]]\n",
      "[13.67409144196952]\n",
      "precision: 100.0 %\n",
      "The background color is 214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31.602649006622517, 34.09933774834437], [55.35502958579882, 67.81656804733728], [76.96902654867256, 98.84955752212389], [103.5390625, 34.3671875]]\n",
      "[14.606662395900065, 23.334150326797385, 10.913675213675214, 14.34676007005254]\n",
      "precision: 50.0 %\n",
      "The background color is 80\n",
      "[[45.391304347826086, 41.316770186335404], [109.4779411764706, 53.845588235294116]]\n",
      "[10.895754518705338, 14.04403948367502]\n",
      "precision: 100.0 %\n",
      "The background color is 191\n",
      "[[35.84848484848485, 101.36363636363636], [103.38815789473684, 76.09868421052632]]\n",
      "[13.631432545201669, 10.67652495378928]\n",
      "precision: 50.0 %\n",
      "The background color is 192\n",
      "[[65.3529411764706, 101.99346405228758], [83.87234042553192, 58.32446808510638]]\n",
      "[14.53072625698324, 15.3004329004329]\n",
      "precision: 50.0 %\n",
      "The background color is 155\n",
      "[[56.65925925925926, 54.65185185185185]]\n",
      "[14.160839160839162]\n",
      "precision: 100.0 %\n",
      "The background color is 51\n",
      "[[30.839285714285715, 71.76785714285714], [63.91743119266055, 56.00917431192661], [92.28813559322033, 34.855932203389834]]\n",
      "[11.745318352059925, 13.07040704070407, 11.283630470016208]\n",
      "precision: 50.0 %\n",
      "The background color is 196\n",
      "[[56.99342105263158, 64.21052631578948], [84.56818181818181, 88.38636363636364]]\n",
      "[10.254771415889925, 5.185714285714286]\n",
      "precision: 50.0 %\n",
      "The background color is 143\n",
      "[[40.85875706214689, 46.36158192090395], [76.0, 29.640449438202246]]\n",
      "[10.343017497523935, 13.62752688172043]\n",
      "precision: 34.0 %\n",
      "The background color is 109\n",
      "[[26.890829694323145, 34.86899563318777], [105.46153846153847, 48.112426035502956]]\n",
      "[14.914960182025029, 11.442708333333334]\n",
      "precision: 0.0 %\n",
      "The background color is 210\n",
      "[[63.65562913907285, 94.60264900662251]]\n",
      "[13.225638051044083]\n",
      "precision: 0.0 %\n",
      "The background color is 89\n",
      "[[32.484375, 87.796875], [53.58039215686274, 57.01176470588236], [91.38323353293413, 97.97005988023952]]\n",
      "[14.827149321266969, 19.468562874251496, 16.541518386714117]\n",
      "precision: 0.0 %\n",
      "The background color is 177\n",
      "[[77.31277533039648, 86.87224669603525]]\n",
      "[14.021496598639455]\n",
      "precision: 0.0 %\n",
      "The background color is 82\n",
      "[[44.96923076923077, 36.353846153846156], [84.90983606557377, 94.0]]\n",
      "[5.3667831057478566, 9.922666666666666]\n",
      "precision: 50.0 %\n",
      "The background color is 193\n",
      "[[57.10091743119266, 69.75229357798165], [66.8135593220339, 26.822033898305083]]\n",
      "[10.051607445008461, 13.868525896414342]\n",
      "precision: 50.0 %\n",
      "The background color is 120\n",
      "[[43.81761006289308, 46.35220125786164], [83.55147058823529, 63.4485294117647], [93.18589743589743, 100.64102564102564]]\n",
      "[10.382340862422998, 12.86230876216968, 15.373341756159192]\n",
      "precision: 34.0 %\n",
      "The background color is 125\n",
      "[[27.030837004405285, 29.56387665198238]]\n",
      "[11.238604143947656]\n",
      "precision: 100.0 %\n",
      "The background color is 95\n",
      "[[97.6993006993007, 83.5104895104895]]\n",
      "[15.113821138211382]\n",
      "precision: 100.0 %\n",
      "The background color is 202\n",
      "[[26.18348623853211, 94.05504587155963], [61.3046357615894, 77.0], [105.44520547945206, 48.37671232876713]]\n",
      "[14.722428748451053, 10.138283681636283, 11.411134903640257]\n",
      "precision: 50.0 %\n",
      "The background color is 172\n",
      "[[37.504273504273506, 35.22649572649573], [89.888, 74.016]]\n",
      "[14.349056603773585, 13.839681133746678]\n",
      "precision: 50.0 %\n",
      "The background color is 79\n",
      "[[47.36666666666667, 42.586666666666666], [78.65420560747664, 34.654205607476634]]\n",
      "[17.550702028081123, 10.998078770413064]\n",
      "precision: 100.0 %\n",
      "The background color is 125\n",
      "[[50.09836065573771, 65.07377049180327], [108.46666666666667, 105.85185185185185], [112.96551724137932, 58.06896551724138]]\n",
      "[10.25068870523416, 12.709205020920502, 15.493736182756079]\n",
      "precision: 100.0 %\n",
      "The background color is 89\n",
      "[[96.83636363636364, 48.872727272727275]]\n",
      "[10.219594594594595]\n",
      "precision: 0.0 %\n",
      "The background color is 213\n",
      "[[42.26162790697674, 73.53488372093024]]\n",
      "[13.626900046061722]\n",
      "precision: 0.0 %\n",
      "The background color is 184\n",
      "[[22.982758620689655, 67.00574712643679], [62.53658536585366, 25.640243902439025], [76.87162162162163, 57.53378378378378]]\n",
      "[11.22164566345441, 15.914792899408283, 15.872463768115942]\n",
      "precision: 34.0 %\n",
      "The background color is 139\n",
      "[[46.47093023255814, 66.13953488372093], [77.35849056603773, 77.9622641509434], [106.14204545454545, 106.91477272727273]]\n",
      "[15.017258883248731, 16.5994747209455, 15.909604519774012]\n",
      "precision: 34.0 %\n",
      "The background color is 121\n",
      "[[29.845070422535212, 83.3849765258216], [68.63492063492063, 37.07142857142857], [104.96470588235294, 64.9235294117647], [99.03472222222223, 101.64583333333333]]\n",
      "[14.098508390304538, 3.3607112616426758, 18.006230529595015, 12.350208457415128]\n",
      "precision: 50.0 %\n",
      "The background color is 151\n",
      "[[21.878048780487806, 83.73780487804878], [97.87793427230046, 56.86854460093897]]\n",
      "[11.018435067595249, 14.07227047146402]\n",
      "precision: 0.0 %\n",
      "The background color is 107\n",
      "[[100.3030303030303, 103.66666666666667]]\n",
      "[14.427662957074721]\n",
      "precision: 100.0 %\n",
      "The background color is 90\n",
      "[[20.106796116504853, 100.10679611650485], [94.39814814814815, 94.76851851851852], [113.35185185185185, 70.35185185185185]]\n",
      "[9.98964218455744, 12.80351262349067, 13.754716981132075]\n",
      "precision: 67.0 %\n",
      "The background color is 139\n",
      "[[44.26315789473684, 71.34502923976608], [79.79113924050633, 107.34810126582279]]\n",
      "[14.26390243902439, 14.948502994011976]\n",
      "precision: 50.0 %\n",
      "The background color is 77\n",
      "[[36.79874213836478, 64.82389937106919], [35.37062937062937, 22.265734265734267], [68.45508982035928, 93.62874251497006]]\n",
      "[15.405850091407679, 11.125680087051142, 17.775015933715743]\n",
      "precision: 34.0 %\n",
      "The background color is 183\n",
      "[[33.614107883817425, 73.35684647302905], [83.61714285714285, 103.48]]\n",
      "[14.323304562268804, 13.020833333333334]\n",
      "precision: 0.0 %\n",
      "The background color is 66\n",
      "[[74.83536585365853, 59.68292682926829], [95.25333333333333, 78.45333333333333], [114.85245901639344, 32.68852459016394]]\n",
      "[14.867882808181315, 19.650655021834062, 14.839481555333998]\n",
      "precision: 34.0 %\n",
      "The background color is 175\n",
      "[[20.285714285714285, 21.142857142857142], [59.13978494623656, 61.95161290322581], [97.63576158940397, 41.90728476821192]]\n",
      "[10.342401500938086, 16.001850138760407, 14.922120418848168]\n",
      "precision: 67.0 %\n",
      "The background color is 51\n",
      "[[76.36134453781513, 57.890756302521005], [91.53358208955224, 90.97014925373135]]\n",
      "[13.80214424951267, 20.130044843049326]\n",
      "precision: 0.0 %\n",
      "The background color is 165\n",
      "[[51.0, 23.519607843137255], [83.65771812080537, 77.3758389261745]]\n",
      "[14.953647143370464, 13.989287964713295]\n",
      "precision: 50.0 %\n",
      "The background color is 145\n",
      "[[37.281879194630875, 79.65771812080537], [67.07471264367815, 36.56896551724138]]\n",
      "[13.128917800118273, 10.276985743380855]\n",
      "precision: 50.0 %\n",
      "The background color is 96\n",
      "[[66.73762376237623, 96.48019801980197], [107.44378698224853, 44.603550295857985]]\n",
      "[13.87891156462585, 14.453947368421053]\n",
      "precision: 50.0 %\n",
      "The background color is 194\n",
      "[[51.01587301587302, 46.03968253968254], [83.81879194630872, 98.36912751677852], [101.51293103448276, 63.30172413793103]]\n",
      "[10.451612903225806, 15.123297002724795, 12.926032660902978]\n",
      "precision: 67.0 %\n",
      "The background color is 173\n",
      "[[76.43005181347151, 74.79792746113989], [54.627272727272725, 41.72727272727273], [89.5034965034965, 30.055944055944057], [110.08333333333333, 93.27272727272727]]\n",
      "[16.540408525754884, 15.45338441890166, 14.151557093425605, 12.897113249444855]\n",
      "precision: 34.0 %\n",
      "The background color is 220\n",
      "[[26.901840490797547, 74.15337423312883], [95.36690647482014, 37.76978417266187], [101.01612903225806, 76.46774193548387]]\n",
      "[10.234591679506934, 13.606338028169015, 11.59577677224736]\n",
      "precision: 100.0 %\n",
      "The background color is 126\n",
      "[[87.62146892655367, 97.52542372881356], [92.17307692307692, 45.41025641025641]]\n",
      "[15.501731815932706, 17.125967628430683]\n",
      "precision: 100.0 %\n",
      "The background color is 183\n",
      "[[62.1875, 90.575], [85.04458598726114, 24.331210191082803], [106.91891891891892, 69.54054054054055]]\n",
      "[14.678899082568808, 14.884661835748792, 14.059050064184852]\n",
      "precision: 100.0 %\n",
      "The background color is 116\n",
      "[[50.945945945945944, 99.98648648648648], [94.41584158415841, 105.87128712871286]]\n",
      "[2.961600865332612, 10.659352142110762]\n",
      "precision: 67.0 %\n",
      "The background color is 56\n",
      "[[33.27433628318584, 101.46460176991151], [103.47407407407407, 55.08148148148148]]\n",
      "[14.689675007190106, 10.210084033613445]\n",
      "precision: 0.0 %\n",
      "The background color is 175\n",
      "[[32.30177514792899, 83.82840236686391], [31.980392156862745, 30.99019607843137], [84.89142857142858, 92.62285714285714]]\n",
      "[14.055610236220472, 9.475409836065573, 13.901497957330912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.0 %\n",
      "The background color is 198\n",
      "[[96.97633136094674, 99.7396449704142]]\n",
      "[15.65844298245614]\n",
      "precision: 100.0 %\n",
      "The background color is 220\n",
      "[[60.224137931034484, 46.172413793103445], [87.80373831775701, 99.7196261682243]]\n",
      "[14.016666666666667, 13.31279069767442]\n",
      "precision: 100.0 %\n",
      "The background color is 223\n",
      "[[96.00813008130082, 72.63414634146342]]\n",
      "[10.448204419889503]\n",
      "precision: 0.0 %\n",
      "The background color is 193\n",
      "[[35.64556962025316, 72.13080168776371]]\n",
      "[14.480278422273782]\n",
      "precision: 0.0 %\n",
      "The background color is 145\n",
      "[[49.895953757225435, 21.589595375722542]]\n",
      "[14.272293752980449]\n",
      "precision: 0.0 %\n",
      "The background color is 159\n",
      "[[64.84210526315789, 25.67763157894737], [106.3089430894309, 101.78048780487805]]\n",
      "[10.501818181818182, 10.16733870967742]\n",
      "precision: 100.0 %\n",
      "The background color is 162\n",
      "[[23.036529680365298, 48.25114155251141], [55.88235294117647, 78.06470588235294]]\n",
      "[17.58745874587459, 14.464464464464465]\n",
      "precision: 50.0 %\n",
      "The background color is 188\n",
      "[[27.67295597484277, 94.937106918239], [45.668508287292816, 59.005524861878456]]\n",
      "[13.739673913043479, 11.704537334762415]\n",
      "precision: 0.0 %\n",
      "The background color is 137\n",
      "[[87.23376623376623, 21.714285714285715]]\n",
      "[13.34608891389983]\n",
      "precision: 0.0 %\n",
      "The background color is 25\n",
      "[[65.73648648648648, 65.73648648648648]]\n",
      "[13.38875305623472]\n",
      "precision: 0.0 %\n",
      "The background color is 217\n",
      "[[47.517587939698494, 24.77386934673367], [78.87677725118483, 47.87677725118483], [112.22222222222223, 105.33333333333333]]\n",
      "[21.245171673819744, 13.895443196004994, 13.926315789473684]\n",
      "precision: 34.0 %\n",
      "The background color is 183\n",
      "[[70.72611464968153, 76.00636942675159], [91.35502958579882, 45.86390532544379], [100.72222222222223, 83.81111111111112]]\n",
      "[14.029026750142288, 17.962893081761006, 13.2569558101473]\n",
      "precision: 67.0 %\n",
      "The background color is 74\n",
      "[[67.29411764705883, 28.00735294117647], [75.04329004329004, 73.04761904761905], [106.8141592920354, 96.66371681415929]]\n",
      "[12.37190635451505, 14.563591703056769, 19.735703245749615]\n",
      "precision: 0.0 %\n",
      "The background color is 97\n",
      "[[22.647058823529413, 98.90441176470588], [71.50299401197604, 39.035928143712574], [108.87209302325581, 99.47674418604652]]\n",
      "[10.521046643913538, 11.630108423686405, 12.306156405990016]\n",
      "precision: 67.0 %\n",
      "The background color is 168\n",
      "[[27.886363636363637, 56.65909090909091], [64.76262626262626, 24.161616161616163], [96.9322033898305, 73.21468926553672], [122.49056603773585, 95.45283018867924]]\n",
      "[17.34767025089606, 14.68864743349569, 15.156748911465893, 23.16701030927835]\n",
      "precision: 100.0 %\n",
      "The background color is 153\n",
      "[[28.5531914893617, 33.88652482269504], [35.30612244897959, 70.66666666666667]]\n",
      "[15.015861027190333, 14.16983606557377]\n",
      "precision: 100.0 %\n",
      "The background color is 144\n",
      "[[74.14965986394557, 75.66666666666667], [84.12422360248448, 35.69565217391305]]\n",
      "[14.329575596816976, 10.746683250414593]\n",
      "precision: 50.0 %\n",
      "The background color is 200\n",
      "[[58.21641791044776, 26.149253731343283], [85.17241379310344, 102.59310344827587]]\n",
      "[10.519039250146456, 14.420438957475994]\n",
      "precision: 100.0 %\n",
      "The background color is 188\n",
      "[[101.87425149700599, 53.862275449101794]]\n",
      "[13.930569430569431]\n",
      "precision: 0.0 %\n",
      "The background color is 46\n",
      "[[66.51515151515152, 100.26515151515152]]\n",
      "[10.159766763848397]\n",
      "precision: 0.0 %\n",
      "The background color is 196\n",
      "[[97.76315789473684, 27.75]]\n",
      "[15.22225475841874]\n",
      "precision: 50.0 %\n",
      "The background color is 142\n",
      "[[44.33913043478261, 81.52173913043478], [87.6687898089172, 21.254777070063696], [106.70552147239263, 44.87116564417178]]\n",
      "[10.48770816812054, 22.06714413607878, 14.534463894967177]\n",
      "precision: 34.0 %\n",
      "The background color is 201\n",
      "[[52.955128205128204, 98.74358974358974], [100.90350877192982, 35.80701754385965]]\n",
      "[13.52751528627015, 15.343565525383708]\n",
      "precision: 50.0 %\n",
      "The background color is 137\n",
      "[[68.46153846153847, 106.14615384615385], [76.46017699115045, 47.26106194690266]]\n",
      "[14.013266998341626, 13.894450489662677]\n",
      "precision: 50.0 %\n",
      "The background color is 203\n",
      "[[47.628787878787875, 28.96969696969697]]\n",
      "[13.486068111455108]\n",
      "precision: 100.0 %\n",
      "The background color is 199\n",
      "[[18.7311320754717, 38.966981132075475], [45.9025974025974, 40.51948051948052]]\n",
      "[24.762534435261706, 12.945414847161572]\n",
      "precision: 50.0 %\n",
      "The background color is 95\n",
      "[[44.880239520958085, 50.874251497005986]]\n",
      "[9.823529411764707]\n",
      "precision: 0.0 %\n",
      "The background color is 117\n",
      "[[79.86178861788618, 39.3739837398374]]\n",
      "[10.462655601659751]\n",
      "precision: 0.0 %\n",
      "The background color is 96\n",
      "[[38.673469387755105, 39.38775510204081], [80.33888888888889, 73.52777777777777]]\n",
      "[13.526760563380282, 14.754098360655737]\n",
      "precision: 100.0 %\n",
      "The background color is 222\n",
      "[[105.65068493150685, 71.02054794520548]]\n",
      "[10.45414418832761]\n",
      "precision: 0.0 %\n",
      "The background color is 76\n",
      "[[26.450331125827816, 24.927152317880793], [26.824242424242424, 69.7939393939394], [93.13658536585366, 23.87317073170732]]\n",
      "[10.899139579349905, 14.187076602397083, 14.83409812919167]\n",
      "precision: 67.0 %\n",
      "The background color is 109\n",
      "[[48.39884393063584, 82.14450867052022]]\n",
      "[13.773124712379198]\n",
      "precision: 0.0 %\n",
      "The background color is 152\n",
      "[[64.03846153846153, 85.46153846153847], [74.17316017316017, 49.16450216450217]]\n",
      "[24.563953488372093, 14.453141928494041]\n",
      "precision: 50.0 %\n",
      "The background color is 123\n",
      "[[64.76571428571428, 100.40571428571428], [88.61935483870968, 43.225806451612904]]\n",
      "[14.264089427107592, 13.611898016997166]\n",
      "precision: 50.0 %\n",
      "The background color is 39\n",
      "[[33.26890756302521, 56.26470588235294]]\n",
      "[14.38029956841838]\n",
      "precision: 0.0 %\n",
      "The background color is 106\n",
      "[[44.16556291390729, 44.211920529801326]]\n",
      "[10.256860098965362]\n",
      "precision: 0.0 %\n",
      "The background color is 174\n",
      "[[31.254545454545454, 36.27272727272727], [87.11206896551724, 97.78448275862068]]\n",
      "[14.595898673100121, 10.263920671243326]\n",
      "precision: 50.0 %\n",
      "The background color is 110\n",
      "[[56.22159090909091, 82.49431818181819]]\n",
      "[14.99322362052275]\n",
      "precision: 100.0 %\n",
      "The background color is 154\n",
      "[[90.89880952380952, 30.922619047619047]]\n",
      "[10.349834983498349]\n",
      "precision: 100.0 %\n",
      "The background color is 123\n",
      "[[48.05084745762712, 22.652542372881356], [71.06285714285714, 59.10857142857143]]\n",
      "[10.998420221169036, 11.787913779830639]\n",
      "precision: 100.0 %\n",
      "The background color is 142\n",
      "[[70.46062992125984, 65.38582677165354]]\n",
      "[15.20886374351721]\n",
      "precision: 100.0 %\n",
      "The background color is 79\n",
      "[[52.140127388535035, 79.3312101910828], [101.31132075471699, 87.93396226415095]]\n",
      "[13.663525498891353, 10.214545454545455]\n",
      "precision: 50.0 %\n",
      "The background color is 19\n",
      "[[77.01915708812261, 41.49233716475096], [82.74866310160428, 41.844919786096256], [74.00909090909092, 71.87272727272727], [77.01915708812261, 41.49233716475096]]\n",
      "[293.625, 20.178303519907676, 10.289115646258503, 293.625]\n",
      "precision: 50.0 %\n",
      "The background color is 95\n",
      "[[35.17088607594937, 48.77215189873418]]\n",
      "[10.45393634840871]\n",
      "precision: 0.0 %\n",
      "The background color is 171\n",
      "[[106.16071428571429, 28.696428571428573], [102.02298850574712, 81.45402298850574]]\n",
      "[14.473846153846154, 11.551316291491798]\n",
      "precision: 50.0 %\n",
      "The background color is 95\n",
      "[[56.22222222222222, 91.75213675213675], [80.5792349726776, 52.73770491803279], [103.01369863013699, 88.4041095890411]]\n",
      "[11.8828125, 11.386943216592996, 18.064406779661017]\n",
      "precision: 0.0 %\n",
      "The background color is 107\n",
      "[[51.774193548387096, 32.49032258064516], [55.588235294117645, 67.78823529411764], [90.69536423841059, 77.17880794701986]]\n",
      "[14.132352941176471, 14.566532258064516, 13.661473936488916]\n",
      "precision: 67.0 %\n",
      "The background color is 70\n",
      "[[49.188976377952756, 106.81102362204724], [76.87301587301587, 30.41269841269841], [98.50568181818181, 96.25]]\n",
      "[12.117956423741548, 13.904632152588556, 10.622770919067216]\n",
      "precision: 0.0 %\n",
      "The background color is 150\n",
      "[[45.84615384615385, 67.34615384615384], [92.9927536231884, 68.21739130434783], [99.51552795031056, 96.3167701863354]]\n",
      "[15.610006414368184, 15.533442088091354, 16.766494178525228]\n",
      "precision: 100.0 %\n",
      "The background color is 110\n",
      "[[25.608695652173914, 26.11111111111111], [86.86896551724138, 85.04827586206896]]\n",
      "[15.024193548387096, 9.84316479400749]\n",
      "precision: 34.0 %\n",
      "The background color is 112\n",
      "[[111.0828025477707, 78.76433121019109]]\n",
      "[15.750159744408945]\n",
      "precision: 0.0 %\n",
      "The background color is 70\n",
      "[[30.089430894308943, 30.11382113821138], [71.16546762589928, 102.61151079136691], [111.62244897959184, 93.79591836734694]]\n",
      "[9.888235294117647, 15.024105754276828, 13.048913043478262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 34.0 %\n",
      "The background color is 88\n",
      "[[65.84210526315789, 28.68421052631579], [95.26589595375722, 83.25433526011561], [101.8780487804878, 43.52439024390244]]\n",
      "[14.126086956521739, 10.946964155084126, 15.008928571428571]\n",
      "precision: 100.0 %\n",
      "The background color is 124\n",
      "[[34.95061728395062, 57.71604938271605], [6.0, 102.0], [74.55172413793103, 80.55172413793103], [68.01785714285714, 112.10714285714286]]\n",
      "[15.556609365737996, 0.011731581417175035, 10.603624901497241, 20.134831460674157]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmax of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'argmax'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-2c64c5df995c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontours_opencv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhierarchy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindContours\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontour\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETR_TREE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCHAIN_APPROX_SIMPLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mmax_piece_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcontours_opencv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0msquare_match\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatchShapes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontours_opencv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmax_piece_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquare_sample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m     \"\"\"\n\u001b[1;32m-> 1004\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# a downstream library like 'pandas'.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Users\\ljsPC\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
     ]
    }
   ],
   "source": [
    "overall_evaluation = {'triangle_total': 0, 'triangle_true_predict': 0,\\\n",
    "                  'square_total': 0, 'square_true_predict': 0,\\\n",
    "                  'circle_total': 0, 'circle_true_predict': 0}\n",
    "\n",
    "for case in range(len(data_list)):\n",
    "    case += 1000\n",
    "    output_file = './output/' + str(case)\n",
    "    if not exists(output_file):\n",
    "        makedirs(output_file)\n",
    "\n",
    "    img = cv2.imread(data_list[case - 1000])\n",
    "\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # medianBlur -> remove the noise\n",
    "    img_gray = cv2.medianBlur(img_gray,5)\n",
    "\n",
    "    # find the background color\n",
    "    boarder_pixel = []\n",
    "    for x in range(img_gray.shape[0]):\n",
    "        for y in range(img_gray.shape[1]):\n",
    "            if x == 0 or y == 0:\n",
    "                boarder_pixel.append(img_gray[x][y])\n",
    "\n",
    "    # assume background color is the pixel value that has the maxi|mum frequency\n",
    "    background_color, frequency = Counter(boarder_pixel).most_common(1)[0]\n",
    "    print('The background color is', background_color)\n",
    "\n",
    "    img_withoutBG = img_gray.copy()\n",
    "    for x in range(img_withoutBG.shape[0]):\n",
    "        for y in range(img_withoutBG.shape[1]):\n",
    "            if(img_withoutBG[x][y] == background_color):\n",
    "                img_withoutBG[x][y] = 0\n",
    "                '''# Floodfill\n",
    "                h, w = img_gray.shape[:2]\n",
    "                mask = np.zeros((h + 2, w + 2), np.uint8)\n",
    "                cv2.floodFill(img_gray, mask, (x, y), 0)\n",
    "                cv2.imwrite(str(count)+'.jpeg',img_gray)\n",
    "                count = count + 1'''\n",
    "\n",
    "    cv2.imwrite(output_file + '/img_withoutBG.jpeg',img_withoutBG)\n",
    "    print_image(output_file + '/img_withoutBG.jpeg')\n",
    "\n",
    "    blob_detector = []\n",
    "    for x in range(img_withoutBG.shape[0]):\n",
    "        for y in range(img_withoutBG.shape[1]):\n",
    "            if(img_withoutBG[x][y] != 0):\n",
    "                blob_detector.append(img_withoutBG[x][y])\n",
    "\n",
    "    # assume blobs have more than 500 pixels\n",
    "    counter_keys = list(Counter(blob_detector).keys())\n",
    "    blob_colors = [x for x in counter_keys if Counter(blob_detector)[x] > 300]\n",
    "\n",
    "    img_noNoise = img_withoutBG.copy()\n",
    "\n",
    "    # remove the noise (non-blobs-color pixels and small size blobs)\n",
    "    remove_surrounding_noise(img_noNoise, blob_colors)\n",
    "\n",
    "    # medianBlur -> remove the noise\n",
    "    img_noNoise = cv2.medianBlur(img_noNoise,5)\n",
    "\n",
    "    '''#recognize the shapes\n",
    "    for x in range(img_noNoise.shape[0]):\n",
    "        for y in range(img_noNoise.shape[1]):\n",
    "            if(img_noNoise[x][y] in blob_colors):\n",
    "                img_noNoise[x][y] = 255'''\n",
    "\n",
    "    cv2.imwrite(output_file + '/img_noNoise.jpeg',img_noNoise)\n",
    "    print_image(output_file + '/img_noNoise.jpeg')\n",
    "    \n",
    "    obj_num = 1\n",
    "    for color in blob_colors:\n",
    "        blob_image = np.zeros_like(img_noNoise)\n",
    "        for x in range(img_noNoise.shape[0]):\n",
    "            for y in range(img_noNoise.shape[1]):\n",
    "                if img_noNoise[x][y] == color:\n",
    "                    blob_image[x][y] = 255\n",
    "        cv2.imwrite(output_file + '/blob_' + str(obj_num) + '.jpeg', blob_image)\n",
    "        obj_num += 1\n",
    "\n",
    "    contours = boundary_following(img_noNoise, blob_colors)\n",
    "\n",
    "    merged_contour = np.zeros_like(img_noNoise)\n",
    "    for contour in contours:\n",
    "        merged_contour += contour\n",
    "\n",
    "    cv2.imwrite(output_file + '/boundary_following.jpeg', merged_contour)\n",
    "    print_image(output_file + '/boundary_following.jpeg')\n",
    "\n",
    "    _, contours_opencv, hierarchy = cv2.findContours(img_noNoise, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    image_background = np.zeros_like(img_noNoise)\n",
    "    # contourIdx=-1 draw all contours\n",
    "    opencv_drawContours_result = cv2.drawContours(image_background, contours_opencv, contourIdx=-1, color=255, thickness=1)\n",
    "\n",
    "    cv2.imwrite(output_file + '/opencv_drawContours_result.jpeg',opencv_drawContours_result)\n",
    "    print_image(output_file + '/opencv_drawContours_result.jpeg')\n",
    "\n",
    "    # mark three categories with grayscale value: 80, 160, 240\n",
    "    classified_contours = []\n",
    "    N4_neighbor = [[-1,0],[1,0],[0,-1],[0,1]]\n",
    "    neighbor = [0,0]\n",
    "\n",
    "    for contour in contours:\n",
    "        classified_contour = contour.copy()\n",
    "\n",
    "        for x in range(classified_contour.shape[0]):\n",
    "            for y in range(classified_contour.shape[1]):\n",
    "                # classify each pixel in the contour\n",
    "                if classified_contour[x][y] == 255:\n",
    "                    is_background = False\n",
    "                    is_boundary = False\n",
    "\n",
    "                    # find the characteristics of its neighbors\n",
    "                    for element in N4_neighbor:\n",
    "                        neighbor[0] = x + element[0]\n",
    "                        neighbor[1] = y + element[1]\n",
    "\n",
    "                        # iamge boundary\n",
    "                        if not (neighbor[0] >= 0 and neighbor[1] >=0 and neighbor[0] < img.shape[0] and neighbor[1] < img.shape[1]):\n",
    "                            is_boundary = True\n",
    "                            break\n",
    "                        # background\n",
    "                        elif img_noNoise[neighbor[0]][neighbor[1]] == 0:\n",
    "                            is_background = True\n",
    "                            break\n",
    "\n",
    "                    if(is_background):\n",
    "                        classified_contour[x][y] = 80\n",
    "                    elif(is_boundary):\n",
    "                        classified_contour[x][y] = 160\n",
    "                    # others belongs to contour against other blobs\n",
    "                    else:\n",
    "                        classified_contour[x][y] = 240\n",
    "\n",
    "        classified_contours.append(classified_contour)\n",
    "\n",
    "    # classified_contours contains classification info of each contour\n",
    "    merged_classified_contour = np.zeros_like(img_noNoise)\n",
    "    for contour in classified_contours:\n",
    "        merged_classified_contour += contour\n",
    "\n",
    "    cv2.imwrite(output_file + '/merged_classified_contour.jpeg',merged_classified_contour)\n",
    "    print_image(output_file + '/merged_classified_contour.jpeg')\n",
    "\n",
    "    # find centorids of blobs in order to determine the positions of them in the annotation file\n",
    "    centorids = []\n",
    "    compactness = []\n",
    "\n",
    "    for contour in classified_contours:\n",
    "        sum_contour = [0,0]\n",
    "        pixel_count = 0\n",
    "        blob_area = 0\n",
    "        compute_area= False\n",
    "\n",
    "        for x in range(contour.shape[0]):\n",
    "            for y in range(contour.shape[1]):\n",
    "                if contour[x][y] != 0:\n",
    "                    sum_contour[0] += x\n",
    "                    sum_contour[1] += y\n",
    "                    pixel_count += 1\n",
    "\n",
    "                    if not compute_area:\n",
    "                        blob_area = bfs(img_noNoise, np.zeros_like(img_noNoise), [x,y])\n",
    "                        compute_area = True\n",
    "\n",
    "        centorids.append([sum_contour[0] / pixel_count, sum_contour[1] / pixel_count])\n",
    "        compactness.append(pixel_count ** 2 / blob_area)\n",
    "\n",
    "    print(centorids)\n",
    "    print(compactness)\n",
    "\n",
    "    # ordered contour\n",
    "    original_contours = classified_contours.copy()\n",
    "    for index in range(len(original_contours)):\n",
    "        for x in range(original_contours[index].shape[0]):\n",
    "            for y in range(original_contours[index].shape[1]):\n",
    "                if original_contours[index][x][y] != 80:\n",
    "                    original_contours[index][x][y] = 0\n",
    "\n",
    "    shapes = []\n",
    "    for contour in original_contours:\n",
    "        shape = 0\n",
    "        _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for cnt_piece in contours_opencv:\n",
    "            shape += len(cv2.approxPolyDP(np.array(cnt_piece), 10, closed=False))\n",
    "\n",
    "        shapes.append(shape)\n",
    "\n",
    "    shapes\n",
    "\n",
    "    shape_match = []\n",
    "    square_sample = np.array([[0,0],[0,1],[0,2],[0,3],[0,4],[0,5],\\\n",
    "                              [1,5],[2,5],[3,5],[4,5],[5,5],\\\n",
    "                              [5,4],[5,3],[5,2],[5,1],[5,0],\\\n",
    "                              [4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "    triangle_sample = np.array([[0,0],[1,np.sqrt(3)],[2,2*np.sqrt(3)],[3,3*np.sqrt(3)],\\\n",
    "                                [4,2*np.sqrt(3)],[5,np.sqrt(3)],[6,0],\\\n",
    "                                [5,0],[4,0],[3,0],[2,0],[1,0],[0,0]])\n",
    "\n",
    "    for contour in original_contours:\n",
    "        _, contours_opencv, hierarchy = cv2.findContours(contour, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        max_piece_index = np.argmax([len(x) for x in contours_opencv])\n",
    "\n",
    "        square_match = cv2.matchShapes(contours_opencv[max_piece_index], square_sample, 1, 0)\n",
    "        triangle_match = cv2.matchShapes(contours_opencv[max_piece_index], triangle_sample, 1, 0)\n",
    "\n",
    "        shape_match.append([square_match, triangle_match])\n",
    "\n",
    "    shape_match\n",
    "\n",
    "    clssified_blobs = []\n",
    "    for blob_index in range(len(contours)):\n",
    "        # considered to be circule\n",
    "        if shapes[blob_index] > 10 or (shapes[blob_index] >= 10 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "            clssified_blobs.append('circle')\n",
    "        # considered to be triangle\n",
    "        elif (shape_match[blob_index][1] < 2 and shape_match[blob_index][0] * 3 < shape_match[blob_index][1]) or (shapes[blob_index] >= 6 and shape_match[blob_index][0] > 10 and shape_match[blob_index][1] > 10):\n",
    "            clssified_blobs.append('triangle')\n",
    "        # considered to be square\n",
    "        else:\n",
    "            clssified_blobs.append('square')\n",
    "\n",
    "    clssified_blobs\n",
    "\n",
    "    relevant_annotations = [x for x in annotation_list if str(case) in x]\n",
    "\n",
    "    evaluation = {'triangle_total': 0, 'triangle_true_predict': 0,\\\n",
    "                  'square_total': 0, 'square_true_predict': 0,\\\n",
    "                  'circle_total': 0, 'circle_true_predict': 0}\n",
    "\n",
    "    for file in relevant_annotations:\n",
    "        if 'triangle' in file:\n",
    "            evaluation['triangle_total'] += 1\n",
    "        elif 'square' in file:\n",
    "            evaluation['square_total'] += 1\n",
    "        elif 'circle' in file:\n",
    "            evaluation['circle_total'] += 1\n",
    "\n",
    "        matched_index = -1\n",
    "        verify_img = cv2.imread(file)\n",
    "        verify_img = cv2.cvtColor(verify_img, cv2.COLOR_BGR2GRAY)\n",
    "        for contour_index in range(len(original_contours)):\n",
    "            if matched_index != -1:\n",
    "                break\n",
    "            for x in range(original_contours[contour_index].shape[0]):\n",
    "                for y in range(original_contours[contour_index].shape[1]):\n",
    "                    if original_contours[contour_index][x][y] != 0 and verify_img[x][y] != 0:\n",
    "                        matched_index = contour_index\n",
    "                        break\n",
    "\n",
    "        if clssified_blobs[matched_index] in file:\n",
    "            evaluation[clssified_blobs[matched_index] + '_true_predict'] += 1\n",
    "\n",
    "    evaluation\n",
    "\n",
    "    precision = (evaluation['triangle_true_predict'] + evaluation['square_true_predict'] + evaluation['circle_true_predict']) / \\\n",
    "                (evaluation['triangle_total'] + evaluation['square_total'] + evaluation['circle_total'])\n",
    "\n",
    "    print('precision:', np.ceil(precision * 100), '%')\n",
    "\n",
    "    txt_file = open(output_file + '/Evaluation.txt','w')\n",
    "    txt_file.write(str(evaluation))\n",
    "    txt_file.write('\\n')\n",
    "    txt_file.write('precision:' + str(np.ceil(precision * 100)) + '%')\n",
    "    txt_file.close()\n",
    "    \n",
    "    for key in overall_evaluation.keys():\n",
    "        overall_evaluation[key] += evaluation[key]\n",
    "\n",
    "precision = (overall_evaluation['triangle_true_predict'] + overall_evaluation['square_true_predict'] + overall_evaluation['circle_true_predict']) / \\\n",
    "                (overall_evaluation['triangle_total'] + overall_evaluation['square_total'] + overall_evaluation['circle_total'])\n",
    "\n",
    "txt_file = open('./output/Overall_Evaluation.txt','w')\n",
    "txt_file.write(str(overall_evaluation))\n",
    "txt_file.write('\\n')\n",
    "txt_file.write('precision:' + str(np.ceil(precision * 100)) + '%')\n",
    "txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
